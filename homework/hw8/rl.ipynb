{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IE 534 HW: Reinforcement Learning\n",
    "    v1, Designed for IE 534/CS 547 Deep Learning, Fall 2019 at UIUC\n",
    "\n",
    "In this assignment, we will experiment with the (deep) reinforcement learning algorithms covered in the lecture. In particular, you will implement variants of the popular `DQN` (Deep Q-Network) (1) and `A2C` (Advantage Actor-Critic) (2) algorithms (by the same first author! orz), and test your implementation on both a small example (CartPole problem) and an Atari game (Breakout game). We focus on model-free algorithms rather than model-based ones, because neural nets are easier applicable and more popular nowadays in the model-free setting. (When the system dynamic is known or can be easily inferred, model-based can sometimes do better.)\n",
    "\n",
    "The assignment breaks into **three parts**:\n",
    "\n",
    "- **In Part I** (50 pts), you basically need to follow the instructions in this notebook to do a little bit of coding. We'll be able to see if your code trains by testing against the CartPole environment provided by the OpenAI gym package. We'll generate some plots that are required for grading.\n",
    "\n",
    "- **In Part II** (40 pts), you'll copy your code onto Blue Waters (or actually any good server..), and run a much larger-scale experiment with the Breakout game. Hopefully, you can teach the computer to play Breakout in less than half a day! Share your final game score in this notebook. **<font color=red>This part will take at least a day. Please start early!!</font>**\n",
    "\n",
    "- **In Part III** (10 pts), you'll be asked to think about a few questions. These questions are mostly open-ended. Please write down your thoughts on them.\n",
    "\n",
    "Finally, after you finished everything in this notebook **<font color=red>(code snippets C1-C5, plots P1-P5, question answers Q1-Q5)</font>**, please save the notebook, and export to a PDF (or an HTML file), and submit:\n",
    "    \n",
    "1. the **.ipynb notebook and exported .pdf/.html file**, PDF is preferred (I usually do File -> Print Preview -> use Chrome's Save as PDF);\n",
    "\n",
    "2. your code (**Algo.py, Model.py files**);\n",
    "\n",
    "3. job artifacts (**.log files** only, pytorch models and images not required)\n",
    "\n",
    "to Compass 2g for grading.\n",
    "\n",
    "**PS: Remember to save your notebook occasionally as you work through it!**\n",
    "\n",
    "#### References\n",
    "\n",
    "- (1) Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Riedmiller, M., Fidjeland, A.K., Ostrovski, G. and Petersen, S., 2015. Human-level control through deep reinforcement learning. Nature, 518(7540), p.529.\n",
    "- (2) Mnih, V., Badia, A.P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., Silver, D. and Kavukcuoglu, K., 2016, June. Asynchronous methods for deep reinforcement learning. In International conference on machine learning (pp. 1928-1937).\n",
    "- (3) A useful tutorial: https://spinningup.openai.com/en/latest/\n",
    "- (4) *Useful code references*: https://github.com/deepmind/bsuite; https://github.com/openai/baselines; https://github.com/astooke/rlpyt;\n",
    "\n",
    "***\n",
    "First of all, **enter your NetID here** in the cell below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your NetID: afausti2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: DQN and A2C on CartPole\n",
    "***\n",
    "This part is designed to run on your own local laptop/PC.\n",
    "\n",
    "Before you start, there are some python dependencies: `pytorch, gym, numpy, multiprocessing, matplotlib`. Please install them correctly. You can install `pytorch` following instruction here https://pytorch.org/get-started/locally/. The code is compatible with PyTorch 0.4.x ~ 1.x. PyTorch 1.1 with cuda 10.0 worked for me (`conda install pytorch==1.1.0 torchvision==0.3.0 cudatoolkit=10.0 -c pytorch`).\n",
    "\n",
    "Please <font color=red>**always**</font> run the code cell below each time you open this notebook, to make sure `gym` is installed and to enable `autoreload` which **allows code changes to be effective immediately**. So if you changed `Algo.py` or `Model.py` but the test codes are not reflecting your changes, restart the notebook kernel and run this cell!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (0.15.4)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from gym) (1.17.2)\n",
      "Requirement already satisfied: six in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from gym) (1.12.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from gym) (1.3.2)\n",
      "Requirement already satisfied: cloudpickle~=1.2.0 in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from gym) (1.2.2)\n",
      "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from gym) (1.3.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from gym) (4.1.1.26)\n",
      "Requirement already satisfied: future in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from pyglet<=1.3.2,>=1.2.0->gym) (0.18.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install openai gym\n",
    "%pip install gym\n",
    "# enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Code Structure\n",
    "\n",
    "The code is structured in 5 python files:\n",
    "\n",
    "- `Main.py`: contains the main entry point and training loop\n",
    "- `Model.py`: constructs the torch neural network modules\n",
    "- `Env.py`: contains the environment simulations interface, based on openai gym\n",
    "- `Algo.py`: implements the DQN and A2C algorithms\n",
    "- `Replay.py`: implements the experience replay buffer for DQN\n",
    "- `Draw.py`: saves some game snapshots to jpeg files\n",
    "\n",
    "Some parts of the code `Model.py` and `Algo.py` are left blank for you to complete. You are not required to modify the other parts (unless, of course, you want to boost the performance!). This is kind of a minimalist implementation, and might be different from the other code on the internet in details. You're welcomed to improve it,  after you've finished all the required things of this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 OpenAI gym and CartPole environment\n",
    "OpenAI developed python package `gym` a while ago to facilitate RL research. `gym` provides a common interface between the program and the environments. For instance, the code cell below will create the CartPole environment. A window will show up when you run the code. The goal is to keep adjusting the cart so that the pole stays in its upright position.\n",
    "\n",
    "A demo video from OpenAI:\n",
    "<video width=\"320\" controls src=\"http://s3-us-west-2.amazonaws.com/rl-gym-doc/cartpole-no-reset.mp4\" />\n",
    "\n",
    "`gym` also provides interface to Atari games. However, installing package `atari-py` is not easy on Windows/Mac, so we won't demonstrate it here. More info: http://gym.openai.com/docs/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "env = gym.make('CartPole-v1')\n",
    "env.reset()\n",
    "for _ in range(200):\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(env.action_space.sample()) # take a random action\n",
    "    if done: break\n",
    "    time.sleep(0.15)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Deep Q Learning\n",
    "\n",
    "A little recap on DQN. We learned from lecture that Q-Learning is a model-free reinforcement learning algorithm. It falls into the off-policy type algorithm since it can utilize past experiences stored in a buffer. It also falls into the (approximate) dynamic programming type algorithm, since it tries to learn an optimal state-action value function using time difference (TD) errors. Q Learning is particularly interesting because it exploits the optimality structure in MDP. It's related to the Hamilton–Jacobi–Bellman equation in classical control.\n",
    "\n",
    "For MDP\n",
    "$$\n",
    "M = (S,A,P,r,\\gamma)\n",
    "$$\n",
    "where $S$ is the state space, $A$ is the action space, $P$ is the transition dynamic, $r(s,a)$ is a reward function $S\\times A \\mapsto R$, and $\\gamma$ is the discount factor.\n",
    "\n",
    "The tabular case (when $S,A$ are finite), Q-Learning does the following value iteration update repeatedly when collecting experience $(s_t, a_t, r_t)$ ($\\eta$ is the learning rate):\n",
    "$$\n",
    "Q^{new}(s_t, a_t) \\leftarrow Q^{old}(s_t, a_t) + \\eta \\left( r_t + \\gamma \\max_{a'\\in A} Q^{old}(s_t, a') - Q^{old}(s_t, a_t) \\right) .\n",
    "$$\n",
    "\n",
    "With function approximation, meaning model $Q(s,a)$ with a function $Q_{\\theta}(s,a)$ parameterized by $\\theta$, we arrive at the Fitted Q Iteration (FQI) algorithm, or better known as Deep Q Learning if the function class is neural networks. Q-Learning with neural network as function approximator was known long ago, but it was only recently (year 2013) that DeepMind made this algorithm actually work on Atari games. Deep Q Learning iteratively optimize the following objective:\n",
    "$$\n",
    "\\theta_{new} \\leftarrow \\arg\\min_{\\theta} \\mathbb{E}_{(s,a,r,s')\\sim D} \\left( r + \\gamma \\max_{a'\\in A} Q_{\\theta_{old}}(s', a') - Q_{\\theta}(s, a) \\right)^2  .\n",
    "$$\n",
    "\n",
    "Therefore, with a batch of $\\{(s^i,a^i,r^i,s'^i)\\}_{i=1}^N$ sampled from the replay buffer, we can build a loss function $L$ in pytorch:\n",
    "$$\n",
    "L(\\theta) = \\frac1N \\sum_{i=1}^N \\left( r^i + \\gamma \\max_{a'\\in A} Q_{\\theta_{old}}(s'^i, a') - Q_{\\theta}(s^i, a^i) \\right)^2\n",
    ",\n",
    "$$\n",
    "and run the usual gradient descent on $\\theta$ with a pytorch optimizer.\n",
    "\n",
    "\n",
    "#### Exploration\n",
    "Exploration, as the word suggests, refers to explore novel unvisited states in RL. The FQI (or DQN) needs an exploratory datasets to work well. The common way to produce exploratory dataset is through randomization, such as the $\\epsilon$-greedy exploration strategy we will implement in this assignment.\n",
    "- $\\epsilon$-greedy exploration:\n",
    "\n",
    "At training iteration $it$, the agent chooses to play\n",
    "$$\n",
    "a = \\begin{cases}\n",
    "\\arg\\max_a Q_{\\theta}(s, a)      &  \\text{ with probability $1 - \\epsilon_{it}$ },  \\\\\n",
    "\\text{a random action $a \\in A$} &  \\text{ with probability $\\epsilon_{it}$ }.  \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "And $\\epsilon_{it}$ is annealed, for example, linearly from $1$ to $0.01$ as training progresses until iteration $it_{\\text{decay}}$:\n",
    "$$\n",
    "\\epsilon_{it} = \\max\\Big\\{ 0.01, 1 + (0.01-1)\\frac{it}{it_{\\text{decay}}} \\Big\\}.\n",
    "$$\n",
    "\n",
    "#### Two Caveats\n",
    "1. There's an improvement on DQN called Double-DQN with the following loss $L$, which has shown to be empirically more stable than the original DQN loss described above. You may want to implement the improved one in your code:\n",
    "$$\n",
    "L(\\theta) = \\frac1N \\sum_{i=1}^N \\left( r^i + \\gamma Q_{\\theta_{old}}\\big( s'^i, \\arg\\max_{a'\\in A} Q_{\\theta}(s'^i, a' ) \\big) - Q_{\\theta}(s^i, a^i) \\right)^2\n",
    ".\n",
    "$$\n",
    "2. Huber loss (a.k.a smooth L1 loss) is commonly used to reduce the effect of extreme values:\n",
    "$$\n",
    "L(\\theta) = \\frac1N \\sum_{i=1}^N Huber\\left( r^i + \\gamma Q_{\\theta_{old}}\\big( s'^i, \\arg\\max_{a'\\in A} Q_{\\theta}(s'^i, a' ) \\big) - Q_{\\theta}(s^i, a^i) \\right)\n",
    "$$\n",
    "You can look up the pytorch document here: https://pytorch.org/docs/stable/nn.functional.html#smooth-l1-loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C1 (5 pts): Complete the code for the two layered fully connected network class `TwoLayerFCNet` in file `Model.py`\n",
    "And run the cell below to test the output shape of your module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape test passed!\n"
     ]
    }
   ],
   "source": [
    "## Test code\n",
    "from Model import TwoLayerFCNet\n",
    "import torch\n",
    "net = TwoLayerFCNet(n_in=4, n_hidden=16, n_out=5)\n",
    "x = torch.randn(10, 4)\n",
    "y = net(x)\n",
    "assert y.shape == (10, 5), \"ERROR: network output has the wrong shape!\"\n",
    "print (\"Output shape test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C2 (5 pts): Complete the code for $\\epsilon$-greedy exploration strategy in function `DQN.act` in file `Algo.py'\n",
    "And run the cell below to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon-greedy test passed!\n"
     ]
    }
   ],
   "source": [
    "## Test code\n",
    "from Algo import DQN\n",
    "class Nothing: pass\n",
    "dummy = Nothing()\n",
    "dummy.eps_decay = 500000\n",
    "\n",
    "dummy.num_act_steps = 0\n",
    "eps = DQN.compute_epsilon(dummy)\n",
    "assert abs( eps - 1.0 ) < 0.01, \"ERROR: compute_epsilon at t=0 should be 1 but got %f!\" % eps\n",
    "\n",
    "dummy.num_act_steps = 250000\n",
    "eps = DQN.compute_epsilon(dummy)\n",
    "assert abs( eps - 0.505 ) < 0.01, \"ERROR: compute_epsilon at t=250000 should around .505 but got %f!\" % eps\n",
    "\n",
    "dummy.num_act_steps = 500000\n",
    "eps = DQN.compute_epsilon(dummy)\n",
    "assert abs( eps - 0.01 ) < 0.01, \"ERROR: compute_epsilon at t=500000 should be .01 but got %f!\" % eps\n",
    "\n",
    "dummy.num_act_steps = 600000\n",
    "eps = DQN.compute_epsilon(dummy)\n",
    "assert abs( eps - 0.01 ) < 0.01, \"ERROR: compute_epsilon after t=500000 should be .01 but got %f!\" % eps\n",
    "print (\"Epsilon-greedy test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C3 (10 pts): Complete the code for computing the loss function in `DQN.train` in file `Algo.py`\n",
    "And run the cell below to verify your code decreses the loss value in one iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters to optimize: [('fc1.weight', torch.Size([128, 10]), True), ('fc1.bias', torch.Size([128]), True), ('fc2.weight', torch.Size([3, 128]), True), ('fc2.bias', torch.Size([3]), True)] \n",
      "\n",
      "0.1998388022184372 > 0.19550158083438873 ?\n",
      "DQN.train test passed!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Algo import DQN\n",
    "class Nothing: pass\n",
    "dummy_obs_space, dummy_act_space = Nothing(), Nothing()\n",
    "dummy_obs_space.shape = [10]\n",
    "dummy_act_space.n = 3\n",
    "\n",
    "dqn = DQN(dummy_obs_space, dummy_act_space, batch_size=2)\n",
    "\n",
    "for t in range(3):\n",
    "    dqn.observe([np.random.randn(10).astype('float32')], [np.random.randint(3)],\n",
    "                [(np.random.randn(10).astype('float32'), np.random.rand(), False, None)])\n",
    "\n",
    "b = dqn.replay.cur_batch\n",
    "loss1 = dqn.train()\n",
    "dqn.replay.cur_batch = b\n",
    "loss2 = dqn.train()\n",
    "\n",
    "print (loss1, '>', loss2, '?')\n",
    "assert loss2 < loss1, \"DQN.train should reduce loss on the same batch\"\n",
    "\n",
    "print (\"DQN.train test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### P1 (10 pts): Run DQN on CartPole and plot the learning curve (i.e. averaged episodic reward against env steps).\n",
    "Your code should be able to achieve **>150** averaged reward in 10000 iterations (20000 simulation steps) in only a few minutes. This is a good indication that the implementation is correct. It's ok that the curve is not always monotonically increasing because of randomness in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(algo='dqn', batch_size=64, checkpoint_freq=20000, discount=0.996, ent_coef=0.01, env='CartPole-v1', eps_decay=4000, frame_skip=1, frame_stack=4, load='', log='log.txt', lr=0.001, niter=10000, nproc=2, parallel_env=0, print_freq=200, replay_size=20000, save_dir='cartpole_dqn/', target_update=1000, train_freq=1, train_start=100, value_coef=0.5)\n",
      "observation space: Box(4,)\n",
      "action space: Discrete(2)\n",
      "running on device cuda\n",
      "parameters to optimize: [('fc1.weight', torch.Size([128, 4]), True), ('fc1.bias', torch.Size([128]), True), ('fc2.weight', torch.Size([2, 128]), True), ('fc2.bias', torch.Size([2]), True)] \n",
      "\n",
      "obses on reset: 2 x (4,) float32\n",
      "iter    200 |loss   0.01 |n_ep    20 |ep_len   19.6 |ep_rew  19.60 |raw_ep_rew  19.60 |env_step    400 |time 00:00 rem 00:47\n",
      "iter    400 |loss   0.00 |n_ep    39 |ep_len   20.9 |ep_rew  20.89 |raw_ep_rew  20.89 |env_step    800 |time 00:02 rem 01:01\n",
      "iter    600 |loss   0.00 |n_ep    59 |ep_len   20.9 |ep_rew  20.94 |raw_ep_rew  20.94 |env_step   1200 |time 00:04 rem 01:04\n",
      "iter    800 |loss   0.00 |n_ep    79 |ep_len   18.9 |ep_rew  18.89 |raw_ep_rew  18.89 |env_step   1600 |time 00:05 rem 01:05\n",
      "iter   1000 |loss   0.00 |n_ep    99 |ep_len   19.1 |ep_rew  19.08 |raw_ep_rew  19.08 |env_step   2000 |time 00:07 rem 01:05\n",
      "iter   1200 |loss   0.02 |n_ep   120 |ep_len   19.1 |ep_rew  19.13 |raw_ep_rew  19.13 |env_step   2400 |time 00:08 rem 01:04\n",
      "iter   1400 |loss   0.03 |n_ep   138 |ep_len   22.5 |ep_rew  22.53 |raw_ep_rew  22.53 |env_step   2800 |time 00:10 rem 01:03\n",
      "iter   1600 |loss   0.02 |n_ep   163 |ep_len   15.7 |ep_rew  15.69 |raw_ep_rew  15.69 |env_step   3200 |time 00:11 rem 01:02\n",
      "iter   1800 |loss   0.02 |n_ep   190 |ep_len   14.9 |ep_rew  14.94 |raw_ep_rew  14.94 |env_step   3600 |time 00:13 rem 01:01\n",
      "iter   2000 |loss   0.03 |n_ep   214 |ep_len   17.6 |ep_rew  17.58 |raw_ep_rew  17.58 |env_step   4000 |time 00:15 rem 01:00\n",
      "iter   2200 |loss   0.03 |n_ep   237 |ep_len   17.5 |ep_rew  17.50 |raw_ep_rew  17.50 |env_step   4400 |time 00:16 rem 00:59\n",
      "iter   2400 |loss   0.03 |n_ep   249 |ep_len   29.5 |ep_rew  29.47 |raw_ep_rew  29.47 |env_step   4800 |time 00:18 rem 00:58\n",
      "iter   2600 |loss   0.03 |n_ep   267 |ep_len   23.2 |ep_rew  23.21 |raw_ep_rew  23.21 |env_step   5200 |time 00:20 rem 00:56\n",
      "iter   2800 |loss   0.02 |n_ep   280 |ep_len   33.5 |ep_rew  33.50 |raw_ep_rew  33.50 |env_step   5600 |time 00:21 rem 00:55\n",
      "iter   3000 |loss   0.02 |n_ep   293 |ep_len   33.2 |ep_rew  33.17 |raw_ep_rew  33.17 |env_step   6000 |time 00:23 rem 00:54\n",
      "iter   3200 |loss   0.04 |n_ep   300 |ep_len   35.6 |ep_rew  35.65 |raw_ep_rew  35.65 |env_step   6400 |time 00:25 rem 00:53\n",
      "iter   3400 |loss   0.02 |n_ep   304 |ep_len   58.1 |ep_rew  58.14 |raw_ep_rew  58.14 |env_step   6800 |time 00:26 rem 00:52\n",
      "iter   3600 |loss   0.05 |n_ep   308 |ep_len   78.3 |ep_rew  78.26 |raw_ep_rew  78.26 |env_step   7200 |time 00:28 rem 00:50\n",
      "iter   3800 |loss   0.04 |n_ep   310 |ep_len   94.1 |ep_rew  94.07 |raw_ep_rew  94.07 |env_step   7600 |time 00:30 rem 00:49\n",
      "iter   4000 |loss   0.04 |n_ep   313 |ep_len  109.5 |ep_rew 109.51 |raw_ep_rew 109.51 |env_step   8000 |time 00:32 rem 00:48\n",
      "iter   4200 |loss   0.05 |n_ep   315 |ep_len  124.4 |ep_rew 124.41 |raw_ep_rew 124.41 |env_step   8400 |time 00:34 rem 00:47\n",
      "iter   4400 |loss   0.03 |n_ep   317 |ep_len  144.5 |ep_rew 144.51 |raw_ep_rew 144.51 |env_step   8800 |time 00:36 rem 00:45\n",
      "iter   4600 |loss   0.06 |n_ep   318 |ep_len  151.5 |ep_rew 151.46 |raw_ep_rew 151.46 |env_step   9200 |time 00:37 rem 00:44\n",
      "iter   4800 |loss   0.02 |n_ep   319 |ep_len  165.4 |ep_rew 165.41 |raw_ep_rew 165.41 |env_step   9600 |time 00:39 rem 00:42\n",
      "iter   5000 |loss   0.04 |n_ep   321 |ep_len  181.2 |ep_rew 181.19 |raw_ep_rew 181.19 |env_step  10000 |time 00:41 rem 00:41\n",
      "iter   5200 |loss   0.02 |n_ep   323 |ep_len  186.6 |ep_rew 186.65 |raw_ep_rew 186.65 |env_step  10400 |time 00:43 rem 00:40\n",
      "iter   5400 |loss   0.08 |n_ep   325 |ep_len  187.9 |ep_rew 187.94 |raw_ep_rew 187.94 |env_step  10800 |time 00:44 rem 00:38\n",
      "iter   5600 |loss   0.08 |n_ep   327 |ep_len  197.9 |ep_rew 197.91 |raw_ep_rew 197.91 |env_step  11200 |time 00:46 rem 00:36\n",
      "iter   5800 |loss   0.11 |n_ep   329 |ep_len  206.1 |ep_rew 206.10 |raw_ep_rew 206.10 |env_step  11600 |time 00:48 rem 00:34\n",
      "iter   6000 |loss   0.07 |n_ep   331 |ep_len  206.1 |ep_rew 206.10 |raw_ep_rew 206.10 |env_step  12000 |time 00:50 rem 00:33\n",
      "iter   6200 |loss   0.01 |n_ep   332 |ep_len  205.7 |ep_rew 205.69 |raw_ep_rew 205.69 |env_step  12400 |time 00:51 rem 00:31\n",
      "iter   6400 |loss   0.01 |n_ep   333 |ep_len  210.9 |ep_rew 210.92 |raw_ep_rew 210.92 |env_step  12800 |time 00:53 rem 00:29\n",
      "iter   6600 |loss   0.03 |n_ep   335 |ep_len  222.5 |ep_rew 222.47 |raw_ep_rew 222.47 |env_step  13200 |time 00:54 rem 00:28\n",
      "iter   6800 |loss   0.19 |n_ep   336 |ep_len  221.5 |ep_rew 221.52 |raw_ep_rew 221.52 |env_step  13600 |time 00:56 rem 00:26\n",
      "iter   7000 |loss   0.01 |n_ep   338 |ep_len  238.5 |ep_rew 238.48 |raw_ep_rew 238.48 |env_step  14000 |time 00:58 rem 00:24\n",
      "iter   7200 |loss   0.09 |n_ep   340 |ep_len  233.7 |ep_rew 233.66 |raw_ep_rew 233.66 |env_step  14400 |time 00:59 rem 00:23\n",
      "iter   7400 |loss   0.06 |n_ep   343 |ep_len  216.4 |ep_rew 216.39 |raw_ep_rew 216.39 |env_step  14800 |time 01:01 rem 00:21\n",
      "iter   7600 |loss   0.01 |n_ep   343 |ep_len  216.4 |ep_rew 216.39 |raw_ep_rew 216.39 |env_step  15200 |time 01:03 rem 00:19\n",
      "iter   7800 |loss   0.10 |n_ep   345 |ep_len  241.8 |ep_rew 241.80 |raw_ep_rew 241.80 |env_step  15600 |time 01:04 rem 00:18\n",
      "iter   8000 |loss   0.05 |n_ep   347 |ep_len  233.0 |ep_rew 233.03 |raw_ep_rew 233.03 |env_step  16000 |time 01:06 rem 00:16\n",
      "iter   8200 |loss   0.02 |n_ep   349 |ep_len  231.8 |ep_rew 231.82 |raw_ep_rew 231.82 |env_step  16400 |time 01:07 rem 00:14\n",
      "iter   8400 |loss   0.17 |n_ep   350 |ep_len  232.5 |ep_rew 232.54 |raw_ep_rew 232.54 |env_step  16800 |time 01:09 rem 00:13\n",
      "iter   8600 |loss   0.03 |n_ep   352 |ep_len  238.5 |ep_rew 238.48 |raw_ep_rew 238.48 |env_step  17200 |time 01:11 rem 00:11\n",
      "iter   8800 |loss   0.14 |n_ep   354 |ep_len  242.6 |ep_rew 242.61 |raw_ep_rew 242.61 |env_step  17600 |time 01:12 rem 00:09\n",
      "iter   9000 |loss   0.12 |n_ep   355 |ep_len  241.9 |ep_rew 241.85 |raw_ep_rew 241.85 |env_step  18000 |time 01:14 rem 00:08\n",
      "iter   9200 |loss   0.00 |n_ep   357 |ep_len  236.5 |ep_rew 236.53 |raw_ep_rew 236.53 |env_step  18400 |time 01:15 rem 00:06\n",
      "iter   9400 |loss   0.12 |n_ep   358 |ep_len  234.1 |ep_rew 234.08 |raw_ep_rew 234.08 |env_step  18800 |time 01:17 rem 00:04\n",
      "iter   9600 |loss   0.08 |n_ep   360 |ep_len  238.2 |ep_rew 238.19 |raw_ep_rew 238.19 |env_step  19200 |time 01:19 rem 00:03\n",
      "iter   9800 |loss   0.16 |n_ep   362 |ep_len  231.8 |ep_rew 231.84 |raw_ep_rew 231.84 |env_step  19600 |time 01:20 rem 00:01\n",
      "save checkpoint to cartpole_dqn/9999.pth\n"
     ]
    }
   ],
   "source": [
    "%run Main.py  \\\n",
    "    --niter 10000   \\\n",
    "    --env CartPole-v1   \\\n",
    "    --algo dqn  \\\n",
    "    --nproc 2   \\\n",
    "    --lr 0.001  \\\n",
    "    --train_freq 1  \\\n",
    "    --train_start 100   \\\n",
    "    --replay_size 20000 \\\n",
    "    --batch_size 64     \\\n",
    "    --discount 0.996    \\\n",
    "    --target_update 1000    \\\n",
    "    --eps_decay 4000    \\\n",
    "    --print_freq 200    \\\n",
    "    --checkpoint_freq 20000 \\\n",
    "    --save_dir cartpole_dqn \\\n",
    "    --log log.txt \\\n",
    "    --parallel_env 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_curve(logfile, title=None):\n",
    "    lines = open(logfile, 'r').readlines()\n",
    "    lines = [l.split() for l in lines if l[:4] == 'iter']\n",
    "    steps = [int(l[13]) for l in lines]\n",
    "    rewards = [float(l[11]) for l in lines]\n",
    "    plt.plot(steps, rewards)\n",
    "    plt.xlabel('env steps'); plt.ylabel('avg episode reward'); plt.grid(True)\n",
    "    if title: plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log is saved to `'cartpole_dqn/log.txt'`. Let's plot the running averaged episode reward curve during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curve('cartpole_dqn/log.txt', 'CartPole DQN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Actor-Critic Algorithm\n",
    "\n",
    "Policy gradient methods are another class of algorithms that originated from viewing the RL problem as a mathematical optimization problem. Recall that the objective of RL is to maximize the expected cumulative reward the agent gets, namely\n",
    "$$\n",
    "\\max_{\\pi} J(\\pi) := \\mathbb{E}_{ (s_t,a_t,r_t)\\sim D^{\\pi} } \\left[ \\sum_{t=0}^{\\infty} \\gamma^t r_t \\right]\n",
    "$$\n",
    "where $D^{\\pi}$ is the distribution of trajectories induced by policy $\\pi$, and inside the expectation is the random variable representing the discounted cumulative reward and $J$ is the reward (or cost) functional. Essentially, we want to optimize the policy $\\pi$.\n",
    "\n",
    "The most straightforward way is to run gradient update on the parameter $\\theta$ of a *parameterized* policy $\\pi_{\\theta}$. One such algorithm is the so-called `Advantage Actor-Critic (A2C)`. A2C is an on-policy policy optimization type algorithm. While collecting on-policy data, we iteratively run gradient ascent:\n",
    "$$\n",
    "\\theta_{new} \\leftarrow \\theta_{old} + \\eta { \\hat \\nabla_{\\theta} } J(\\pi_{\\theta_{old}})\n",
    "$$\n",
    "with a Monte Carlo estimate ${ \\hat \\nabla_{\\theta} } J$ of the true gradient $\\nabla_{\\theta} J$. The true gradient writes as (by Policy Gradient Theorem and some manipulations):\n",
    "$$\n",
    "\\nabla_{\\theta} J(\\pi_{\\theta_{old}}) = \\mathbb{E}_{ (s_t,a_t,r_t)\\sim D^{ \\pi_{\\theta_{old}} } } \\sum_{t=0}^{\\infty} \\left( \\nabla_{\\theta} \\log \\pi_{\\theta_{old}} (s_t, a_t) \\left( \\sum_{t'=t}^{\\infty} \\gamma^{t'-t} r_{t'} - V^{ \\pi_{\\theta_{old}} }(s_t) \\right) \\right)  .\n",
    "$$\n",
    "The quantity in the inner-most parentheses $A(s_t, a_t) = Q(s_t, a_t) - V(s_t) = (\\mathbb{E} \\sum_{t'=t}^{\\infty} \\gamma^{t'-t} r_{t'}) - V(s_t)$ is called the *Advantage* function (not very rigoriously speaking...). That's why it's called **Advantage** Actor-Critic. More on A2C: https://arxiv.org/abs/1506.02438.\n",
    "\n",
    "And the Monte Carlo estimate of the gradient is\n",
    "$$\n",
    "{ \\hat \\nabla_{\\theta} } J(\\pi_{\\theta_{old}}) = \\frac1{NT}  \\sum_{i=1}^N \\sum_{t=0}^T \\left( \\nabla_{\\theta} \\log \\pi_{\\theta_{old}} (s_t^{i}, a_t^{i}) \\left( \\sum_{t'=t}^T \\gamma^{t'-t} r_{t'}^{i} - V_{\\phi_{old}}(s_t^{i}) \\right) \\right)\n",
    "$$\n",
    "where $V_{\\phi_{old}}$ is introduced as a *parameterized* estimate for $V^{ \\pi_{\\theta_{old}} }$, which can also be a neural network. So $V_{\\phi}$ is the **critic** and $\\pi_{\\theta}$ is the **actor**. We can construct a specific loss function in pytorch that gives ${ \\hat \\nabla_{\\theta} } J$. $V_{\\phi_{old}}$ is trained with SGD on a L2 loss function. It's further common practice to add an entropy bonus loss term to encourage maximum entropy solution, to facilitate exploration and avoid getting stuck in local minima. We shall clarify these loss functions in the following summarization.\n",
    "\n",
    "#### Summarizing a variant of the A2C algorithm:\n",
    "> For many iterations repeat:\n",
    "1. Collect $N$ independent trajectories $\\{ (s_t^{i},a_t^{i},r_t^{i})_{t=0}^T \\}_{i=1}^{N}$ by running policy $\\pi_{\\theta}$ for maximum $T$ steps;\n",
    "2. Compute the loss function for the policy parameter $\\theta$:\n",
    "$$\n",
    "L_{policy}(\\theta) = \\frac1{NT} \\sum_{i=1}^N \\sum_{t=0}^T \\left( \\log \\pi_{\\theta} (s_t^{i}, a_t^{i}) \\left( \\sum_{t'=t}^T \\gamma^{t'-t} r_{t'}^{i} - V_{\\phi}(s_t^{i}) \\right) \\right)\n",
    "$$\n",
    "Compute the entropy term for $\\theta$:\n",
    "$$\n",
    "L_{entropy}(\\theta) = \\frac1{NT} \\sum_{i=1}^N \\sum_{t=0}^T \\left( - \\sum_{a\\in A} \\pi_{\\theta}(s_t^{i}, a) \\log \\pi_{\\theta}(s_t^{i}, a) \\right)\n",
    "$$\n",
    "Compute the loss for value function parameter $\\phi$:\n",
    "$$\n",
    "L_{value}(\\phi) = \\frac1{NT} \\sum_{i=1}^N \\sum_{t=0}^T \\left( \\sum_{t'=t}^T \\gamma^{t'-t} r_{t'}^{i} - V_{\\phi}(s_t^{i}) \\right)^2\n",
    "$$\n",
    "3. Use pytorch auto-differentiation and optimizer to do one gradient step on $(\\theta, \\phi)$ with the overall loss:\n",
    "$$\n",
    "L(\\theta, \\phi) = - L_{policy} - \\lambda_{ent} L_{entropy} + \\lambda_{val} L_{value}\n",
    "$$\n",
    "where $\\lambda_{ent}$ and $\\lambda_{val}$ are coefficients to balances the loss terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C4 (10 pts): Complete the code for computing the advantange, entropy and loss function in `A2C.train` in file `Algo.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### P2 (10 pts): Run A2C on CartPole and plot the learning curve (i.e. averaged episodic reward against training iteration).\n",
    "Your code should be able to achieve **>150** averaged reward in 10000 iterations (40000 simulation steps) in only a few minutes. This is a good indication that the implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(algo='a2c', batch_size=64, checkpoint_freq=20000, discount=0.996, ent_coef=0.01, env='CartPole-v1', eps_decay=200000, frame_skip=1, frame_stack=4, load='', log='log.txt', lr=0.001, niter=10000, nproc=4, parallel_env=0, print_freq=200, replay_size=1000000, save_dir='cartpole_a2c/', target_update=2500, train_freq=16, train_start=0, value_coef=0.01)\n",
      "observation space: Box(4,)\n",
      "action space: Discrete(2)\n",
      "running on device cuda\n",
      "shared net = False, parameters to optimize: [('fc1.weight', torch.Size([128, 4]), True), ('fc1.bias', torch.Size([128]), True), ('fc2.weight', torch.Size([2, 128]), True), ('fc2.bias', torch.Size([2]), True), ('fc1.weight', torch.Size([128, 4]), True), ('fc1.bias', torch.Size([128]), True), ('fc2.weight', torch.Size([1, 128]), True), ('fc2.bias', torch.Size([1]), True)] \n",
      "\n",
      "obses on reset: 4 x (4,) float32\n",
      "iter    200 |loss   1.00 |n_ep    39 |ep_len   18.2 |ep_rew  18.23 |raw_ep_rew  18.23 |env_step    800 |time 00:00 rem 00:27\n",
      "iter    400 |loss   0.93 |n_ep    70 |ep_len   23.1 |ep_rew  23.15 |raw_ep_rew  23.15 |env_step   1600 |time 00:01 rem 00:25\n",
      "iter    600 |loss   0.91 |n_ep   104 |ep_len   23.9 |ep_rew  23.92 |raw_ep_rew  23.92 |env_step   2400 |time 00:01 rem 00:25\n",
      "iter    800 |loss   0.83 |n_ep   135 |ep_len   25.2 |ep_rew  25.20 |raw_ep_rew  25.20 |env_step   3200 |time 00:02 rem 00:24\n",
      "iter   1000 |loss   0.81 |n_ep   166 |ep_len   25.2 |ep_rew  25.15 |raw_ep_rew  25.15 |env_step   4000 |time 00:02 rem 00:23\n",
      "iter   1200 |loss   0.78 |n_ep   198 |ep_len   25.8 |ep_rew  25.80 |raw_ep_rew  25.80 |env_step   4800 |time 00:03 rem 00:23\n",
      "iter   1400 |loss   0.76 |n_ep   227 |ep_len   28.0 |ep_rew  28.01 |raw_ep_rew  28.01 |env_step   5600 |time 00:03 rem 00:22\n",
      "iter   1600 |loss   0.73 |n_ep   254 |ep_len   28.5 |ep_rew  28.54 |raw_ep_rew  28.54 |env_step   6400 |time 00:04 rem 00:22\n",
      "iter   1800 |loss   0.76 |n_ep   276 |ep_len   34.9 |ep_rew  34.91 |raw_ep_rew  34.91 |env_step   7200 |time 00:04 rem 00:21\n",
      "iter   2000 |loss   0.63 |n_ep   299 |ep_len   36.6 |ep_rew  36.59 |raw_ep_rew  36.59 |env_step   8000 |time 00:05 rem 00:21\n",
      "iter   2200 |loss   0.80 |n_ep   327 |ep_len   28.7 |ep_rew  28.71 |raw_ep_rew  28.71 |env_step   8800 |time 00:05 rem 00:20\n",
      "iter   2400 |loss   0.58 |n_ep   352 |ep_len   29.5 |ep_rew  29.52 |raw_ep_rew  29.52 |env_step   9600 |time 00:06 rem 00:20\n",
      "iter   2600 |loss   0.56 |n_ep   371 |ep_len   37.0 |ep_rew  37.05 |raw_ep_rew  37.05 |env_step  10400 |time 00:06 rem 00:19\n",
      "iter   2800 |loss   0.94 |n_ep   392 |ep_len   31.7 |ep_rew  31.74 |raw_ep_rew  31.74 |env_step  11200 |time 00:07 rem 00:19\n",
      "iter   3000 |loss   0.65 |n_ep   413 |ep_len   34.4 |ep_rew  34.44 |raw_ep_rew  34.44 |env_step  12000 |time 00:08 rem 00:18\n",
      "iter   3200 |loss   0.89 |n_ep   434 |ep_len   34.9 |ep_rew  34.89 |raw_ep_rew  34.89 |env_step  12800 |time 00:08 rem 00:18\n",
      "iter   3400 |loss   0.59 |n_ep   454 |ep_len   36.6 |ep_rew  36.58 |raw_ep_rew  36.58 |env_step  13600 |time 00:09 rem 00:17\n",
      "iter   3600 |loss   0.11 |n_ep   472 |ep_len   45.8 |ep_rew  45.75 |raw_ep_rew  45.75 |env_step  14400 |time 00:09 rem 00:17\n",
      "iter   3800 |loss   0.63 |n_ep   484 |ep_len   46.4 |ep_rew  46.38 |raw_ep_rew  46.38 |env_step  15200 |time 00:10 rem 00:16\n",
      "iter   4000 |loss   0.54 |n_ep   499 |ep_len   55.7 |ep_rew  55.65 |raw_ep_rew  55.65 |env_step  16000 |time 00:10 rem 00:16\n",
      "iter   4200 |loss   0.98 |n_ep   507 |ep_len   60.7 |ep_rew  60.73 |raw_ep_rew  60.73 |env_step  16800 |time 00:11 rem 00:15\n",
      "iter   4400 |loss   0.55 |n_ep   518 |ep_len   73.6 |ep_rew  73.60 |raw_ep_rew  73.60 |env_step  17600 |time 00:11 rem 00:14\n",
      "iter   4600 |loss   0.64 |n_ep   528 |ep_len   89.9 |ep_rew  89.91 |raw_ep_rew  89.91 |env_step  18400 |time 00:12 rem 00:14\n",
      "iter   4800 |loss   0.49 |n_ep   538 |ep_len   79.2 |ep_rew  79.20 |raw_ep_rew  79.20 |env_step  19200 |time 00:12 rem 00:13\n",
      "iter   5000 |loss   0.90 |n_ep   545 |ep_len   97.5 |ep_rew  97.45 |raw_ep_rew  97.45 |env_step  20000 |time 00:13 rem 00:13\n",
      "iter   5200 |loss   0.31 |n_ep   551 |ep_len  111.7 |ep_rew 111.74 |raw_ep_rew 111.74 |env_step  20800 |time 00:13 rem 00:12\n",
      "iter   5400 |loss   0.85 |n_ep   555 |ep_len  133.8 |ep_rew 133.83 |raw_ep_rew 133.83 |env_step  21600 |time 00:14 rem 00:12\n",
      "iter   5600 |loss   0.17 |n_ep   563 |ep_len  137.2 |ep_rew 137.24 |raw_ep_rew 137.24 |env_step  22400 |time 00:15 rem 00:11\n",
      "iter   5800 |loss   0.82 |n_ep   566 |ep_len  145.3 |ep_rew 145.26 |raw_ep_rew 145.26 |env_step  23200 |time 00:15 rem 00:11\n",
      "iter   6000 |loss   0.89 |n_ep   572 |ep_len  142.9 |ep_rew 142.87 |raw_ep_rew 142.87 |env_step  24000 |time 00:16 rem 00:10\n",
      "iter   6200 |loss   0.09 |n_ep   577 |ep_len  144.2 |ep_rew 144.23 |raw_ep_rew 144.23 |env_step  24800 |time 00:16 rem 00:10\n",
      "iter   6400 |loss  -0.03 |n_ep   582 |ep_len  148.8 |ep_rew 148.76 |raw_ep_rew 148.76 |env_step  25600 |time 00:17 rem 00:09\n",
      "iter   6600 |loss   0.90 |n_ep   588 |ep_len  154.4 |ep_rew 154.39 |raw_ep_rew 154.39 |env_step  26400 |time 00:17 rem 00:09\n",
      "iter   6800 |loss   0.71 |n_ep   593 |ep_len  155.0 |ep_rew 154.98 |raw_ep_rew 154.98 |env_step  27200 |time 00:18 rem 00:08\n",
      "iter   7000 |loss   0.14 |n_ep   597 |ep_len  148.6 |ep_rew 148.61 |raw_ep_rew 148.61 |env_step  28000 |time 00:18 rem 00:08\n",
      "iter   7200 |loss   0.83 |n_ep   601 |ep_len  175.3 |ep_rew 175.26 |raw_ep_rew 175.26 |env_step  28800 |time 00:19 rem 00:07\n",
      "iter   7400 |loss   0.74 |n_ep   604 |ep_len  181.0 |ep_rew 181.02 |raw_ep_rew 181.02 |env_step  29600 |time 00:20 rem 00:07\n",
      "iter   7600 |loss   0.92 |n_ep   608 |ep_len  193.5 |ep_rew 193.48 |raw_ep_rew 193.48 |env_step  30400 |time 00:20 rem 00:06\n",
      "iter   7800 |loss   0.32 |n_ep   614 |ep_len  187.2 |ep_rew 187.20 |raw_ep_rew 187.20 |env_step  31200 |time 00:21 rem 00:05\n",
      "iter   8000 |loss   0.04 |n_ep   618 |ep_len  192.9 |ep_rew 192.93 |raw_ep_rew 192.93 |env_step  32000 |time 00:21 rem 00:05\n",
      "iter   8200 |loss   1.04 |n_ep   620 |ep_len  200.5 |ep_rew 200.54 |raw_ep_rew 200.54 |env_step  32800 |time 00:22 rem 00:04\n",
      "iter   8400 |loss   0.58 |n_ep   623 |ep_len  209.2 |ep_rew 209.23 |raw_ep_rew 209.23 |env_step  33600 |time 00:22 rem 00:04\n",
      "iter   8600 |loss   0.67 |n_ep   628 |ep_len  218.5 |ep_rew 218.47 |raw_ep_rew 218.47 |env_step  34400 |time 00:23 rem 00:03\n",
      "iter   8800 |loss  -0.05 |n_ep   632 |ep_len  215.2 |ep_rew 215.19 |raw_ep_rew 215.19 |env_step  35200 |time 00:23 rem 00:03\n",
      "iter   9000 |loss  -0.19 |n_ep   638 |ep_len  179.1 |ep_rew 179.12 |raw_ep_rew 179.12 |env_step  36000 |time 00:24 rem 00:02\n",
      "iter   9200 |loss   0.87 |n_ep   640 |ep_len  199.9 |ep_rew 199.91 |raw_ep_rew 199.91 |env_step  36800 |time 00:24 rem 00:02\n",
      "iter   9400 |loss  -0.05 |n_ep   646 |ep_len  190.4 |ep_rew 190.37 |raw_ep_rew 190.37 |env_step  37600 |time 00:25 rem 00:01\n",
      "iter   9600 |loss   0.20 |n_ep   649 |ep_len  169.0 |ep_rew 169.01 |raw_ep_rew 169.01 |env_step  38400 |time 00:25 rem 00:01\n",
      "iter   9800 |loss  -0.14 |n_ep   655 |ep_len  196.9 |ep_rew 196.85 |raw_ep_rew 196.85 |env_step  39200 |time 00:26 rem 00:00\n",
      "save checkpoint to cartpole_a2c/9999.pth\n"
     ]
    }
   ],
   "source": [
    "%run Main.py  \\\n",
    "    --niter 10000   \\\n",
    "    --env CartPole-v1   \\\n",
    "    --algo a2c  \\\n",
    "    --nproc 4   \\\n",
    "    --lr 0.001  \\\n",
    "    --train_freq 16 \\\n",
    "    --train_start 0 \\\n",
    "    --batch_size 64     \\\n",
    "    --discount 0.996    \\\n",
    "    --value_coef 0.01    \\\n",
    "    --print_freq 200    \\\n",
    "    --checkpoint_freq 20000 \\\n",
    "    --save_dir cartpole_a2c \\\n",
    "    --log log.txt \\\n",
    "    --parallel_env 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curve('cartpole_a2c/log.txt', 'CartPole A2C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's play a little bit with the trained agent. The neural net parameters are saved to the `cartpole_dqn` and `cartpole_a2c` folders. The cell below will open a window showing one episode play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared net = False, parameters to optimize: [('fc1.weight', torch.Size([128, 4]), True), ('fc1.bias', torch.Size([128]), True), ('fc2.weight', torch.Size([2, 128]), True), ('fc2.bias', torch.Size([2]), True), ('fc1.weight', torch.Size([128, 4]), True), ('fc1.bias', torch.Size([128]), True), ('fc2.weight', torch.Size([1, 128]), True), ('fc2.bias', torch.Size([1]), True)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gym\n",
    "import Algo\n",
    "env = gym.make('CartPole-v1')\n",
    "agent = Algo.ActorCritic(env.observation_space, env.action_space)\n",
    "agent.load('cartpole_a2c/9999.pth')\n",
    "state = env.reset()\n",
    "for _ in range(120):\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(agent.act([state])[0])\n",
    "    if done: break\n",
    "    time.sleep(0.1)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Solve the Atari Breakout game\n",
    "***\n",
    "In this part, you'll train your agent to play Breakout with the BlueWaters cluster. I have provided the job scripts for you. Please upload your `Algo.py` and `Model.py` completed in **Part I** to your BlueWaters folder. And submit the following two jobs respectively:\n",
    "```\n",
    "qsub run_dqn.pbs\n",
    "qsub run_a2c.pbs\n",
    "```\n",
    "\n",
    "The jobs are set to run for at most **14 hours**. **<font color=red>Please start early!!</font>** You might be able to reach the desired score (>= 200 reward) before 14 hours - You can stop the training early if you wish. Then please collect the resulting `breakout_dqn/log.txt` and `breakout_a2c/log.txt` files into the same folder as this Jupyter notebook's. Rename them as `log_breakout_dqn.txt` and `log_breakout_a2c.txt`.\n",
    "\n",
    "BTW, there's an Atari PC simulator: https://stella-emu.github.io/ I spent a lot of time playing them..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C5 (10 pts): Complete the code for the CNN with 3 conv layers and 3 fc layers in class `SimpleCNN` in file `Model.py`\n",
    "And verify the output shape with the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN output shape test passed!\n"
     ]
    }
   ],
   "source": [
    "## Test code\n",
    "from Model import SimpleCNN\n",
    "import torch\n",
    "net = SimpleCNN()\n",
    "x = torch.randn(2, 4, 84, 84)\n",
    "y = net(x)\n",
    "assert y.shape == (2, 4), \"ERROR: network output has the wrong shape!\"\n",
    "print (\"CNN output shape test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### P3 (10 pts): Run the following cell to generate a DQN learning curve.\n",
    "The *maximum* average episodic reward on this curve should be larger than $200$ for full credit. (It's ok if the final reward is not as high.) The typical value is around $300$. You get 70% credit if $100 \\le$ average episodic reward $< 200$, 50% credit if $50 \\le$ average episodic reward $< 100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[atari] in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (0.15.4)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from gym[atari]) (4.1.1.26)\n",
      "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from gym[atari]) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from gym[atari]) (1.17.2)\n",
      "Requirement already satisfied: six in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from gym[atari]) (1.12.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from gym[atari]) (1.3.2)\n",
      "Requirement already satisfied: cloudpickle~=1.2.0 in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from gym[atari]) (1.2.2)\n",
      "Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from gym[atari]) (0.2.6)\n",
      "Requirement already satisfied: Pillow; extra == \"atari\" in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from gym[atari]) (6.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\penti\\miniconda3\\envs\\cs547\\lib\\site-packages (from pyglet<=1.3.2,>=1.2.0->gym[atari]) (0.18.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gym[atari]\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(algo='dqn', batch_size=32, checkpoint_freq=500000, discount=0.99, ent_coef=0.01, env='BreakoutDeterministic-v4', eps_decay=200000, frame_skip=1, frame_stack=4, load='', log='log.txt', lr=0.0001, niter=2000000, nproc=2, parallel_env=0, print_freq=500, replay_size=1000000, save_dir='breakout_dqn/', target_update=2500, train_freq=2, train_start=5000, value_coef=0.5)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mD:\\Users\\Penti\\cs547\\homework\\hw8\\Main.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParallelEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe_skip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe_stack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLocalEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe_skip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe_stack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[0mlogprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'observation space:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobs_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mlogprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'action space:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Penti\\cs547\\homework\\hw8\\Env.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, nproc, frame_skip, frame_stack, save_img_dir)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe_skip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe_stack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe_skip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m  \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnproc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Penti\\cs547\\homework\\hw8\\Env.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe_skip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe_stack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe_skip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m  \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnproc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\site-packages\\gym\\envs\\registration.py\u001b[0m in \u001b[0;36mmake\u001b[1;34m(id, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\site-packages\\gym\\envs\\registration.py\u001b[0m in \u001b[0;36mmake\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Making new env: %s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[1;31m# We used to have people override _reset/_step rather than\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;31m# reset/step. Set _gym_disable_underscore_compat = True on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\site-packages\\gym\\envs\\registration.py\u001b[0m in \u001b[0;36mmake\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m             \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\site-packages\\gym\\envs\\registration.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mmod_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\site-packages\\gym\\envs\\atari\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matari\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matari_env\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAtariEnv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\site-packages\\gym\\envs\\atari\\atari_env.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0matari_py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     raise error.DependencyNotInstalled(\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\site-packages\\atari_py\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0male_python_interface\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_game_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"atari_roms\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\site-packages\\atari_py\\ale_python_interface.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     ale_lib = cdll.LoadLibrary(os.path.join(os.path.dirname(__file__),\n\u001b[1;32m---> 18\u001b[1;33m                                             'ale_interface/ale_c.dll'))\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0male_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mALE_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[0mcdll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\cs547\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found"
     ]
    }
   ],
   "source": [
    "%run Main.py  \\\n",
    "    --save_dir breakout_dqn \\\n",
    "    --parallel_env 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve('log_breakout_dqn.txt', 'Breakout DQN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### P4 (10 pts): Run the following cell to generate an A2C learning curve.\n",
    "The *maximum* average episodic reward on this curve should be larger than $150$ for full credit. (It's ok if the final reward is not as high.) The typical value is around $250$. You get 70% credit if $50 \\le$ average episodic reward $< 150$, and 50% credit if $20 \\le$ average episodic reward $< 50$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve('log_breakout_a2c.txt', 'Breakout A2C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### P5 (10 pts): Collect and visualize some game frames by running the script `Draw.py` on BlueWaters.\n",
    "(1) `module load python/2.0.0` and run `Draw.py` on BlueWaters (it's ok to run this locally, no need to start a job).\n",
    "\n",
    "(2) Download the result `breakout_imgs` folder from BlueWaters to the folder containing this Jupyter notebook, and run the following cell. You should see some animation of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "imgs = sorted(os.listdir('breakout_imgs'))\n",
    "#imgs = [plt.imread('breakout_imgs/' + img) for img in imgs]\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "pimg = None\n",
    "for img in imgs:\n",
    "    img = plt.imread('breakout_imgs/' + img)\n",
    "    if pimg:\n",
    "        pimg.set_data(img)\n",
    "    else:\n",
    "        pimg = plt.imshow(img)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Questions (10 pts)\n",
    "***\n",
    "\n",
    "These are open-ended questions. The purpose is to encourage you to think (a bit) more deeply about these algorithms. You get full points as long as you write a few sentences that make sense and show some thinking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q1 (2 pts): Why would people want to do function approximation rather than using tabular algorithm (on discretized S,A spaces if necessary)? Bringing function approximation has caused numerous problems theoretically (e.g. not guaranteed to converge), so it seems not worth it..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer: I don't know. People enjoy \"neuralizing\" things I guess.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q2 (2 pts): Q-Learning seems good... it's theoretically sound (at least seems to be), the performance is also good. Why would many people actually prefer policy gradient type algorithms in some practical problems?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer: I don't know. I like Q learning. The name is cute. Anyone watch StarTrek?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3 (2 pts): Does the policy gradient algorithm (A2C) we implemented here extend to continuous action space? How would you do that? Hint: What is a reasonable distribution assumption for policy $\\pi_{\\theta}(a|s)$ if $a$ lives in continuous space?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer: I don't know. Maybe normalizing flow?? OK, people really do this..(arXiv:1905.06893) Hot area + hot area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q4 (2 pts): The policy gradient algorithm (A2C) we implemented uses on-policy data. Can you think of a way to extend it to utilize off-policy data? Hint: Importance sampling, needs some approximation though"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer: I don't know. Do random math tricks or pray?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5 (2 pts): How to compare different RL algorithms? When can I say one algorithm is better than the other? Hint: This question is quite open. Think about speed, complexity, tasks, etc."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer: I don't know. Just pick one you like, they're equally bad.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
