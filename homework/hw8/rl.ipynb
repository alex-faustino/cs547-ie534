{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IE 534 HW: Reinforcement Learning\n",
    "    v1, Designed for IE 534/CS 547 Deep Learning, Fall 2019 at UIUC\n",
    "\n",
    "In this assignment, we will experiment with the (deep) reinforcement learning algorithms covered in the lecture. In particular, you will implement variants of the popular `DQN` (Deep Q-Network) (1) and `A2C` (Advantage Actor-Critic) (2) algorithms (by the same first author! orz), and test your implementation on both a small example (CartPole problem) and an Atari game (Breakout game). We focus on model-free algorithms rather than model-based ones, because neural nets are easier applicable and more popular nowadays in the model-free setting. (When the system dynamic is known or can be easily inferred, model-based can sometimes do better.)\n",
    "\n",
    "The assignment breaks into **three parts**:\n",
    "\n",
    "- **In Part I** (50 pts), you basically need to follow the instructions in this notebook to do a little bit of coding. We'll be able to see if your code trains by testing against the CartPole environment provided by the OpenAI gym package. We'll generate some plots that are required for grading.\n",
    "\n",
    "- **In Part II** (40 pts), you'll copy your code onto Blue Waters (or actually any good server..), and run a much larger-scale experiment with the Breakout game. Hopefully, you can teach the computer to play Breakout in less than half a day! Share your final game score in this notebook. **<font color=red>This part will take at least a day. Please start early!!</font>**\n",
    "\n",
    "- **In Part III** (10 pts), you'll be asked to think about a few questions. These questions are mostly open-ended. Please write down your thoughts on them.\n",
    "\n",
    "Finally, after you finished everything in this notebook **<font color=red>(code snippets C1-C5, plots P1-P5, question answers Q1-Q5)</font>**, please save the notebook, and export to a PDF (or an HTML file), and submit:\n",
    "    \n",
    "1. the **.ipynb notebook and exported .pdf/.html file**, PDF is preferred (I usually do File -> Print Preview -> use Chrome's Save as PDF);\n",
    "\n",
    "2. your code (**Algo.py, Model.py files**);\n",
    "\n",
    "3. job artifacts (**.log files** only, pytorch models and images not required)\n",
    "\n",
    "to Compass 2g for grading.\n",
    "\n",
    "**PS: Remember to save your notebook occasionally as you work through it!**\n",
    "\n",
    "#### References\n",
    "\n",
    "- (1) Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Riedmiller, M., Fidjeland, A.K., Ostrovski, G. and Petersen, S., 2015. Human-level control through deep reinforcement learning. Nature, 518(7540), p.529.\n",
    "- (2) Mnih, V., Badia, A.P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., Silver, D. and Kavukcuoglu, K., 2016, June. Asynchronous methods for deep reinforcement learning. In International conference on machine learning (pp. 1928-1937).\n",
    "- (3) A useful tutorial: https://spinningup.openai.com/en/latest/\n",
    "- (4) *Useful code references*: https://github.com/deepmind/bsuite; https://github.com/openai/baselines; https://github.com/astooke/rlpyt;\n",
    "\n",
    "***\n",
    "First of all, **enter your NetID here** in the cell below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your NetID: afausti2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: DQN and A2C on CartPole\n",
    "***\n",
    "This part is designed to run on your own local laptop/PC.\n",
    "\n",
    "Before you start, there are some python dependencies: `pytorch, gym, numpy, multiprocessing, matplotlib`. Please install them correctly. You can install `pytorch` following instruction here https://pytorch.org/get-started/locally/. The code is compatible with PyTorch 0.4.x ~ 1.x. PyTorch 1.1 with cuda 10.0 worked for me (`conda install pytorch==1.1.0 torchvision==0.3.0 cudatoolkit=10.0 -c pytorch`).\n",
    "\n",
    "Please <font color=red>**always**</font> run the code cell below each time you open this notebook, to make sure `gym` is installed and to enable `autoreload` which **allows code changes to be effective immediately**. So if you changed `Algo.py` or `Model.py` but the test codes are not reflecting your changes, restart the notebook kernel and run this cell!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /Users/alex/miniconda3/envs/cs547/lib/python3.7/site-packages (0.15.4)\n",
      "Requirement already satisfied: cloudpickle~=1.2.0 in /Users/alex/miniconda3/envs/cs547/lib/python3.7/site-packages (from gym) (1.2.2)\n",
      "Requirement already satisfied: opencv-python in /Users/alex/miniconda3/envs/cs547/lib/python3.7/site-packages (from gym) (4.1.1.26)\n",
      "Requirement already satisfied: six in /Users/alex/miniconda3/envs/cs547/lib/python3.7/site-packages (from gym) (1.12.0)\n",
      "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /Users/alex/miniconda3/envs/cs547/lib/python3.7/site-packages (from gym) (1.3.2)\n",
      "Requirement already satisfied: scipy in /Users/alex/miniconda3/envs/cs547/lib/python3.7/site-packages (from gym) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /Users/alex/miniconda3/envs/cs547/lib/python3.7/site-packages (from gym) (1.16.4)\n",
      "Requirement already satisfied: future in /Users/alex/miniconda3/envs/cs547/lib/python3.7/site-packages (from pyglet<=1.3.2,>=1.2.0->gym) (0.18.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install openai gym\n",
    "%pip install gym\n",
    "# enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Code Structure\n",
    "\n",
    "The code is structured in 5 python files:\n",
    "\n",
    "- `Main.py`: contains the main entry point and training loop\n",
    "- `Model.py`: constructs the torch neural network modules\n",
    "- `Env.py`: contains the environment simulations interface, based on openai gym\n",
    "- `Algo.py`: implements the DQN and A2C algorithms\n",
    "- `Replay.py`: implements the experience replay buffer for DQN\n",
    "- `Draw.py`: saves some game snapshots to jpeg files\n",
    "\n",
    "Some parts of the code `Model.py` and `Algo.py` are left blank for you to complete. You are not required to modify the other parts (unless, of course, you want to boost the performance!). This is kind of a minimalist implementation, and might be different from the other code on the internet in details. You're welcomed to improve it,  after you've finished all the required things of this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 OpenAI gym and CartPole environment\n",
    "OpenAI developed python package `gym` a while ago to facilitate RL research. `gym` provides a common interface between the program and the environments. For instance, the code cell below will create the CartPole environment. A window will show up when you run the code. The goal is to keep adjusting the cart so that the pole stays in its upright position.\n",
    "\n",
    "A demo video from OpenAI:\n",
    "<video width=\"320\" controls src=\"http://s3-us-west-2.amazonaws.com/rl-gym-doc/cartpole-no-reset.mp4\" />\n",
    "\n",
    "`gym` also provides interface to Atari games. However, installing package `atari-py` is not easy on Windows/Mac, so we won't demonstrate it here. More info: http://gym.openai.com/docs/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "env = gym.make('CartPole-v1')\n",
    "env.reset()\n",
    "for _ in range(200):\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(env.action_space.sample()) # take a random action\n",
    "    if done: break\n",
    "    time.sleep(0.15)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Deep Q Learning\n",
    "\n",
    "A little recap on DQN. We learned from lecture that Q-Learning is a model-free reinforcement learning algorithm. It falls into the off-policy type algorithm since it can utilize past experiences stored in a buffer. It also falls into the (approximate) dynamic programming type algorithm, since it tries to learn an optimal state-action value function using time difference (TD) errors. Q Learning is particularly interesting because it exploits the optimality structure in MDP. It's related to the Hamilton–Jacobi–Bellman equation in classical control.\n",
    "\n",
    "For MDP\n",
    "$$\n",
    "M = (S,A,P,r,\\gamma)\n",
    "$$\n",
    "where $S$ is the state space, $A$ is the action space, $P$ is the transition dynamic, $r(s,a)$ is a reward function $S\\times A \\mapsto R$, and $\\gamma$ is the discount factor.\n",
    "\n",
    "The tabular case (when $S,A$ are finite), Q-Learning does the following value iteration update repeatedly when collecting experience $(s_t, a_t, r_t)$ ($\\eta$ is the learning rate):\n",
    "$$\n",
    "Q^{new}(s_t, a_t) \\leftarrow Q^{old}(s_t, a_t) + \\eta \\left( r_t + \\gamma \\max_{a'\\in A} Q^{old}(s_t, a') - Q^{old}(s_t, a_t) \\right) .\n",
    "$$\n",
    "\n",
    "With function approximation, meaning model $Q(s,a)$ with a function $Q_{\\theta}(s,a)$ parameterized by $\\theta$, we arrive at the Fitted Q Iteration (FQI) algorithm, or better known as Deep Q Learning if the function class is neural networks. Q-Learning with neural network as function approximator was known long ago, but it was only recently (year 2013) that DeepMind made this algorithm actually work on Atari games. Deep Q Learning iteratively optimize the following objective:\n",
    "$$\n",
    "\\theta_{new} \\leftarrow \\arg\\min_{\\theta} \\mathbb{E}_{(s,a,r,s')\\sim D} \\left( r + \\gamma \\max_{a'\\in A} Q_{\\theta_{old}}(s', a') - Q_{\\theta}(s, a) \\right)^2  .\n",
    "$$\n",
    "\n",
    "Therefore, with a batch of $\\{(s^i,a^i,r^i,s'^i)\\}_{i=1}^N$ sampled from the replay buffer, we can build a loss function $L$ in pytorch:\n",
    "$$\n",
    "L(\\theta) = \\frac1N \\sum_{i=1}^N \\left( r^i + \\gamma \\max_{a'\\in A} Q_{\\theta_{old}}(s'^i, a') - Q_{\\theta}(s^i, a^i) \\right)^2\n",
    ",\n",
    "$$\n",
    "and run the usual gradient descent on $\\theta$ with a pytorch optimizer.\n",
    "\n",
    "\n",
    "#### Exploration\n",
    "Exploration, as the word suggests, refers to explore novel unvisited states in RL. The FQI (or DQN) needs an exploratory datasets to work well. The common way to produce exploratory dataset is through randomization, such as the $\\epsilon$-greedy exploration strategy we will implement in this assignment.\n",
    "- $\\epsilon$-greedy exploration:\n",
    "\n",
    "At training iteration $it$, the agent chooses to play\n",
    "$$\n",
    "a = \\begin{cases}\n",
    "\\arg\\max_a Q_{\\theta}(s, a)      &  \\text{ with probability $1 - \\epsilon_{it}$ },  \\\\\n",
    "\\text{a random action $a \\in A$} &  \\text{ with probability $\\epsilon_{it}$ }.  \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "And $\\epsilon_{it}$ is annealed, for example, linearly from $1$ to $0.01$ as training progresses until iteration $it_{\\text{decay}}$:\n",
    "$$\n",
    "\\epsilon_{it} = \\max\\Big\\{ 0.01, 1 + (0.01-1)\\frac{it}{it_{\\text{decay}}} \\Big\\}.\n",
    "$$\n",
    "\n",
    "#### Two Caveats\n",
    "1. There's an improvement on DQN called Double-DQN with the following loss $L$, which has shown to be empirically more stable than the original DQN loss described above. You may want to implement the improved one in your code:\n",
    "$$\n",
    "L(\\theta) = \\frac1N \\sum_{i=1}^N \\left( r^i + \\gamma Q_{\\theta_{old}}\\big( s'^i, \\arg\\max_{a'\\in A} Q_{\\theta}(s'^i, a' ) \\big) - Q_{\\theta}(s^i, a^i) \\right)^2\n",
    ".\n",
    "$$\n",
    "2. Huber loss (a.k.a smooth L1 loss) is commonly used to reduce the effect of extreme values:\n",
    "$$\n",
    "L(\\theta) = \\frac1N \\sum_{i=1}^N Huber\\left( r^i + \\gamma Q_{\\theta_{old}}\\big( s'^i, \\arg\\max_{a'\\in A} Q_{\\theta}(s'^i, a' ) \\big) - Q_{\\theta}(s^i, a^i) \\right)\n",
    "$$\n",
    "You can look up the pytorch document here: https://pytorch.org/docs/stable/nn.functional.html#smooth-l1-loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C1 (5 pts): Complete the code for the two layered fully connected network class `TwoLayerFCNet` in file `Model.py`\n",
    "And run the cell below to test the output shape of your module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape test passed!\n"
     ]
    }
   ],
   "source": [
    "## Test code\n",
    "from Model import TwoLayerFCNet\n",
    "import torch\n",
    "net = TwoLayerFCNet(n_in=4, n_hidden=16, n_out=5)\n",
    "x = torch.randn(10, 4)\n",
    "y = net(x)\n",
    "assert y.shape == (10, 5), \"ERROR: network output has the wrong shape!\"\n",
    "print (\"Output shape test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C2 (5 pts): Complete the code for $\\epsilon$-greedy exploration strategy in function `DQN.act` in file `Algo.py'\n",
    "And run the cell below to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon-greedy test passed!\n"
     ]
    }
   ],
   "source": [
    "## Test code\n",
    "from Algo import DQN\n",
    "class Nothing: pass\n",
    "dummy = Nothing()\n",
    "dummy.eps_decay = 500000\n",
    "\n",
    "dummy.num_act_steps = 0\n",
    "eps = DQN.compute_epsilon(dummy)\n",
    "assert abs( eps - 1.0 ) < 0.01, \"ERROR: compute_epsilon at t=0 should be 1 but got %f!\" % eps\n",
    "\n",
    "dummy.num_act_steps = 250000\n",
    "eps = DQN.compute_epsilon(dummy)\n",
    "assert abs( eps - 0.505 ) < 0.01, \"ERROR: compute_epsilon at t=250000 should around .505 but got %f!\" % eps\n",
    "\n",
    "dummy.num_act_steps = 500000\n",
    "eps = DQN.compute_epsilon(dummy)\n",
    "assert abs( eps - 0.01 ) < 0.01, \"ERROR: compute_epsilon at t=500000 should be .01 but got %f!\" % eps\n",
    "\n",
    "dummy.num_act_steps = 600000\n",
    "eps = DQN.compute_epsilon(dummy)\n",
    "assert abs( eps - 0.01 ) < 0.01, \"ERROR: compute_epsilon after t=500000 should be .01 but got %f!\" % eps\n",
    "print (\"Epsilon-greedy test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C3 (10 pts): Complete the code for computing the loss function in `DQN.train` in file `Algo.py`\n",
    "And run the cell below to verify your code decreses the loss value in one iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters to optimize: [('fc1.weight', torch.Size([128, 10]), True), ('fc1.bias', torch.Size([128]), True), ('fc2.weight', torch.Size([3, 128]), True), ('fc2.bias', torch.Size([3]), True)] \n",
      "\n",
      "0.31915923953056335 > 0.3147554099559784 ?\n",
      "DQN.train test passed!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Algo import DQN\n",
    "class Nothing: pass\n",
    "dummy_obs_space, dummy_act_space = Nothing(), Nothing()\n",
    "dummy_obs_space.shape = [10]\n",
    "dummy_act_space.n = 3\n",
    "\n",
    "dqn = DQN(dummy_obs_space, dummy_act_space, batch_size=2)\n",
    "\n",
    "for t in range(3):\n",
    "    dqn.observe([np.random.randn(10).astype('float32')], [np.random.randint(3)],\n",
    "                [(np.random.randn(10).astype('float32'), np.random.rand(), False, None)])\n",
    "\n",
    "b = dqn.replay.cur_batch\n",
    "loss1 = dqn.train()\n",
    "dqn.replay.cur_batch = b\n",
    "loss2 = dqn.train()\n",
    "\n",
    "print (loss1, '>', loss2, '?')\n",
    "assert loss2 < loss1, \"DQN.train should reduce loss on the same batch\"\n",
    "\n",
    "print (\"DQN.train test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### P1 (10 pts): Run DQN on CartPole and plot the learning curve (i.e. averaged episodic reward against env steps).\n",
    "Your code should be able to achieve **>150** averaged reward in 10000 iterations (20000 simulation steps) in only a few minutes. This is a good indication that the implementation is correct. It's ok that the curve is not always monotonically increasing because of randomness in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(algo='dqn', batch_size=64, checkpoint_freq=20000, discount=0.996, ent_coef=0.01, env='CartPole-v1', eps_decay=4000, frame_skip=1, frame_stack=4, load='', log='log.txt', lr=0.001, niter=10000, nproc=2, parallel_env=0, print_freq=200, replay_size=20000, save_dir='cartpole_dqn/', target_update=1000, train_freq=1, train_start=100, value_coef=0.5)\n",
      "observation space: Box(4,)\n",
      "action space: Discrete(2)\n",
      "running on device cpu\n",
      "parameters to optimize: [('fc1.weight', torch.Size([128, 4]), True), ('fc1.bias', torch.Size([128]), True), ('fc2.weight', torch.Size([2, 128]), True), ('fc2.bias', torch.Size([2]), True)] \n",
      "\n",
      "obses on reset: 2 x (4,) float32\n",
      "iter    200 |loss   0.01 |n_ep    21 |ep_len   17.3 |ep_rew  17.26 |raw_ep_rew  17.26 |env_step    400 |time 00:00 rem 00:05\n",
      "iter    400 |loss   0.00 |n_ep    39 |ep_len   19.8 |ep_rew  19.78 |raw_ep_rew  19.78 |env_step    800 |time 00:00 rem 00:07\n",
      "iter    600 |loss   0.00 |n_ep    59 |ep_len   19.2 |ep_rew  19.24 |raw_ep_rew  19.24 |env_step   1200 |time 00:00 rem 00:08\n",
      "iter    800 |loss   0.00 |n_ep    76 |ep_len   22.2 |ep_rew  22.21 |raw_ep_rew  22.21 |env_step   1600 |time 00:00 rem 00:08\n",
      "iter   1000 |loss   0.00 |n_ep    97 |ep_len   18.7 |ep_rew  18.67 |raw_ep_rew  18.67 |env_step   2000 |time 00:00 rem 00:08\n",
      "iter   1200 |loss   0.04 |n_ep   115 |ep_len   23.0 |ep_rew  23.01 |raw_ep_rew  23.01 |env_step   2400 |time 00:01 rem 00:08\n",
      "iter   1400 |loss   0.04 |n_ep   137 |ep_len   18.3 |ep_rew  18.27 |raw_ep_rew  18.27 |env_step   2800 |time 00:01 rem 00:08\n",
      "iter   1600 |loss   0.02 |n_ep   163 |ep_len   15.5 |ep_rew  15.48 |raw_ep_rew  15.48 |env_step   3200 |time 00:01 rem 00:08\n",
      "iter   1800 |loss   0.03 |n_ep   188 |ep_len   15.2 |ep_rew  15.22 |raw_ep_rew  15.22 |env_step   3600 |time 00:01 rem 00:07\n",
      "iter   2000 |loss   0.02 |n_ep   217 |ep_len   13.2 |ep_rew  13.16 |raw_ep_rew  13.16 |env_step   4000 |time 00:01 rem 00:07\n",
      "iter   2200 |loss   0.03 |n_ep   244 |ep_len   14.5 |ep_rew  14.55 |raw_ep_rew  14.55 |env_step   4400 |time 00:02 rem 00:07\n",
      "iter   2400 |loss   0.04 |n_ep   261 |ep_len   20.9 |ep_rew  20.94 |raw_ep_rew  20.94 |env_step   4800 |time 00:02 rem 00:07\n",
      "iter   2600 |loss   0.03 |n_ep   276 |ep_len   24.8 |ep_rew  24.76 |raw_ep_rew  24.76 |env_step   5200 |time 00:02 rem 00:07\n",
      "iter   2800 |loss   0.00 |n_ep   289 |ep_len   30.0 |ep_rew  30.04 |raw_ep_rew  30.04 |env_step   5600 |time 00:02 rem 00:07\n",
      "iter   3000 |loss   0.03 |n_ep   301 |ep_len   34.6 |ep_rew  34.64 |raw_ep_rew  34.64 |env_step   6000 |time 00:03 rem 00:07\n",
      "iter   3200 |loss   0.06 |n_ep   309 |ep_len   29.0 |ep_rew  28.96 |raw_ep_rew  28.96 |env_step   6400 |time 00:03 rem 00:06\n",
      "iter   3400 |loss   0.10 |n_ep   313 |ep_len   59.7 |ep_rew  59.69 |raw_ep_rew  59.69 |env_step   6800 |time 00:03 rem 00:06\n",
      "iter   3600 |loss   0.02 |n_ep   318 |ep_len   72.8 |ep_rew  72.82 |raw_ep_rew  72.82 |env_step   7200 |time 00:03 rem 00:06\n",
      "iter   3800 |loss   0.03 |n_ep   322 |ep_len   78.2 |ep_rew  78.19 |raw_ep_rew  78.19 |env_step   7600 |time 00:03 rem 00:06\n",
      "iter   4000 |loss   0.03 |n_ep   328 |ep_len   74.0 |ep_rew  73.96 |raw_ep_rew  73.96 |env_step   8000 |time 00:04 rem 00:06\n",
      "iter   4200 |loss   0.18 |n_ep   331 |ep_len   81.2 |ep_rew  81.19 |raw_ep_rew  81.19 |env_step   8400 |time 00:04 rem 00:05\n",
      "iter   4400 |loss   0.01 |n_ep   335 |ep_len  103.2 |ep_rew 103.23 |raw_ep_rew 103.23 |env_step   8800 |time 00:04 rem 00:05\n",
      "iter   4600 |loss   0.02 |n_ep   337 |ep_len  116.6 |ep_rew 116.65 |raw_ep_rew 116.65 |env_step   9200 |time 00:04 rem 00:05\n",
      "iter   4800 |loss   0.03 |n_ep   341 |ep_len  113.1 |ep_rew 113.08 |raw_ep_rew 113.08 |env_step   9600 |time 00:04 rem 00:05\n",
      "iter   5000 |loss   0.04 |n_ep   344 |ep_len  115.9 |ep_rew 115.91 |raw_ep_rew 115.91 |env_step  10000 |time 00:05 rem 00:05\n",
      "iter   5200 |loss   0.01 |n_ep   347 |ep_len  117.9 |ep_rew 117.92 |raw_ep_rew 117.92 |env_step  10400 |time 00:05 rem 00:04\n",
      "iter   5400 |loss   0.06 |n_ep   348 |ep_len  129.7 |ep_rew 129.73 |raw_ep_rew 129.73 |env_step  10800 |time 00:05 rem 00:04\n",
      "iter   5600 |loss   0.08 |n_ep   350 |ep_len  161.8 |ep_rew 161.84 |raw_ep_rew 161.84 |env_step  11200 |time 00:06 rem 00:04\n",
      "iter   5800 |loss   0.00 |n_ep   352 |ep_len  162.7 |ep_rew 162.67 |raw_ep_rew 162.67 |env_step  11600 |time 00:06 rem 00:04\n",
      "iter   6000 |loss   0.07 |n_ep   354 |ep_len  165.9 |ep_rew 165.91 |raw_ep_rew 165.91 |env_step  12000 |time 00:06 rem 00:04\n",
      "iter   6200 |loss   0.06 |n_ep   356 |ep_len  169.5 |ep_rew 169.50 |raw_ep_rew 169.50 |env_step  12400 |time 00:06 rem 00:04\n",
      "iter   6400 |loss   0.06 |n_ep   358 |ep_len  174.5 |ep_rew 174.53 |raw_ep_rew 174.53 |env_step  12800 |time 00:06 rem 00:03\n",
      "iter   6600 |loss   0.08 |n_ep   360 |ep_len  179.5 |ep_rew 179.51 |raw_ep_rew 179.51 |env_step  13200 |time 00:07 rem 00:03\n",
      "iter   6800 |loss   0.01 |n_ep   363 |ep_len  177.0 |ep_rew 177.05 |raw_ep_rew 177.05 |env_step  13600 |time 00:07 rem 00:03\n",
      "iter   7000 |loss   0.07 |n_ep   364 |ep_len  180.3 |ep_rew 180.34 |raw_ep_rew 180.34 |env_step  14000 |time 00:07 rem 00:03\n",
      "iter   7200 |loss   0.01 |n_ep   366 |ep_len  190.9 |ep_rew 190.87 |raw_ep_rew 190.87 |env_step  14400 |time 00:07 rem 00:03\n",
      "iter   7400 |loss   0.01 |n_ep   368 |ep_len  191.1 |ep_rew 191.11 |raw_ep_rew 191.11 |env_step  14800 |time 00:07 rem 00:02\n",
      "iter   7600 |loss   0.01 |n_ep   370 |ep_len  212.3 |ep_rew 212.25 |raw_ep_rew 212.25 |env_step  15200 |time 00:08 rem 00:02\n",
      "iter   7800 |loss   0.00 |n_ep   371 |ep_len  211.0 |ep_rew 211.03 |raw_ep_rew 211.03 |env_step  15600 |time 00:08 rem 00:02\n",
      "iter   8000 |loss   0.01 |n_ep   372 |ep_len  212.6 |ep_rew 212.62 |raw_ep_rew 212.62 |env_step  16000 |time 00:08 rem 00:02\n",
      "iter   8200 |loss   0.05 |n_ep   374 |ep_len  227.0 |ep_rew 226.98 |raw_ep_rew 226.98 |env_step  16400 |time 00:08 rem 00:01\n",
      "iter   8400 |loss   0.11 |n_ep   376 |ep_len  229.6 |ep_rew 229.63 |raw_ep_rew 229.63 |env_step  16800 |time 00:08 rem 00:01\n",
      "iter   8600 |loss   0.09 |n_ep   377 |ep_len  237.8 |ep_rew 237.77 |raw_ep_rew 237.77 |env_step  17200 |time 00:09 rem 00:01\n",
      "iter   8800 |loss   0.24 |n_ep   379 |ep_len  236.0 |ep_rew 235.99 |raw_ep_rew 235.99 |env_step  17600 |time 00:09 rem 00:01\n",
      "iter   9000 |loss   0.01 |n_ep   380 |ep_len  239.2 |ep_rew 239.19 |raw_ep_rew 239.19 |env_step  18000 |time 00:09 rem 00:01\n",
      "iter   9200 |loss   0.02 |n_ep   382 |ep_len  233.6 |ep_rew 233.58 |raw_ep_rew 233.58 |env_step  18400 |time 00:09 rem 00:00\n",
      "iter   9400 |loss   0.05 |n_ep   384 |ep_len  235.2 |ep_rew 235.20 |raw_ep_rew 235.20 |env_step  18800 |time 00:10 rem 00:00\n",
      "iter   9600 |loss   0.00 |n_ep   387 |ep_len  221.1 |ep_rew 221.15 |raw_ep_rew 221.15 |env_step  19200 |time 00:10 rem 00:00\n",
      "iter   9800 |loss   0.14 |n_ep   388 |ep_len  223.3 |ep_rew 223.33 |raw_ep_rew 223.33 |env_step  19600 |time 00:10 rem 00:00\n",
      "save checkpoint to cartpole_dqn/9999.pth\n"
     ]
    }
   ],
   "source": [
    "%run Main.py  \\\n",
    "    --niter 10000   \\\n",
    "    --env CartPole-v1   \\\n",
    "    --algo dqn  \\\n",
    "    --nproc 2   \\\n",
    "    --lr 0.001  \\\n",
    "    --train_freq 1  \\\n",
    "    --train_start 100   \\\n",
    "    --replay_size 20000 \\\n",
    "    --batch_size 64     \\\n",
    "    --discount 0.996    \\\n",
    "    --target_update 1000    \\\n",
    "    --eps_decay 4000    \\\n",
    "    --print_freq 200    \\\n",
    "    --checkpoint_freq 20000 \\\n",
    "    --save_dir cartpole_dqn \\\n",
    "    --log log.txt \\\n",
    "    --parallel_env 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_curve(logfile, title=None):\n",
    "    lines = open(logfile, 'r').readlines()\n",
    "    lines = [l.split() for l in lines if l[:4] == 'iter']\n",
    "    steps = [int(l[13]) for l in lines]\n",
    "    rewards = [float(l[11]) for l in lines]\n",
    "    plt.plot(steps, rewards)\n",
    "    plt.xlabel('env steps'); plt.ylabel('avg episode reward'); plt.grid(True)\n",
    "    if title: plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log is saved to `'cartpole_dqn/log.txt'`. Let's plot the running averaged episode reward curve during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curve('cartpole_dqn/log.txt', 'CartPole DQN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Actor-Critic Algorithm\n",
    "\n",
    "Policy gradient methods are another class of algorithms that originated from viewing the RL problem as a mathematical optimization problem. Recall that the objective of RL is to maximize the expected cumulative reward the agent gets, namely\n",
    "$$\n",
    "\\max_{\\pi} J(\\pi) := \\mathbb{E}_{ (s_t,a_t,r_t)\\sim D^{\\pi} } \\left[ \\sum_{t=0}^{\\infty} \\gamma^t r_t \\right]\n",
    "$$\n",
    "where $D^{\\pi}$ is the distribution of trajectories induced by policy $\\pi$, and inside the expectation is the random variable representing the discounted cumulative reward and $J$ is the reward (or cost) functional. Essentially, we want to optimize the policy $\\pi$.\n",
    "\n",
    "The most straightforward way is to run gradient update on the parameter $\\theta$ of a *parameterized* policy $\\pi_{\\theta}$. One such algorithm is the so-called `Advantage Actor-Critic (A2C)`. A2C is an on-policy policy optimization type algorithm. While collecting on-policy data, we iteratively run gradient ascent:\n",
    "$$\n",
    "\\theta_{new} \\leftarrow \\theta_{old} + \\eta { \\hat \\nabla_{\\theta} } J(\\pi_{\\theta_{old}})\n",
    "$$\n",
    "with a Monte Carlo estimate ${ \\hat \\nabla_{\\theta} } J$ of the true gradient $\\nabla_{\\theta} J$. The true gradient writes as (by Policy Gradient Theorem and some manipulations):\n",
    "$$\n",
    "\\nabla_{\\theta} J(\\pi_{\\theta_{old}}) = \\mathbb{E}_{ (s_t,a_t,r_t)\\sim D^{ \\pi_{\\theta_{old}} } } \\sum_{t=0}^{\\infty} \\left( \\nabla_{\\theta} \\log \\pi_{\\theta_{old}} (s_t, a_t) \\left( \\sum_{t'=t}^{\\infty} \\gamma^{t'-t} r_{t'} - V^{ \\pi_{\\theta_{old}} }(s_t) \\right) \\right)  .\n",
    "$$\n",
    "The quantity in the inner-most parentheses $A(s_t, a_t) = Q(s_t, a_t) - V(s_t) = (\\mathbb{E} \\sum_{t'=t}^{\\infty} \\gamma^{t'-t} r_{t'}) - V(s_t)$ is called the *Advantage* function (not very rigoriously speaking...). That's why it's called **Advantage** Actor-Critic. More on A2C: https://arxiv.org/abs/1506.02438.\n",
    "\n",
    "And the Monte Carlo estimate of the gradient is\n",
    "$$\n",
    "{ \\hat \\nabla_{\\theta} } J(\\pi_{\\theta_{old}}) = \\frac1{NT}  \\sum_{i=1}^N \\sum_{t=0}^T \\left( \\nabla_{\\theta} \\log \\pi_{\\theta_{old}} (s_t^{i}, a_t^{i}) \\left( \\sum_{t'=t}^T \\gamma^{t'-t} r_{t'}^{i} - V_{\\phi_{old}}(s_t^{i}) \\right) \\right)\n",
    "$$\n",
    "where $V_{\\phi_{old}}$ is introduced as a *parameterized* estimate for $V^{ \\pi_{\\theta_{old}} }$, which can also be a neural network. So $V_{\\phi}$ is the **critic** and $\\pi_{\\theta}$ is the **actor**. We can construct a specific loss function in pytorch that gives ${ \\hat \\nabla_{\\theta} } J$. $V_{\\phi_{old}}$ is trained with SGD on a L2 loss function. It's further common practice to add an entropy bonus loss term to encourage maximum entropy solution, to facilitate exploration and avoid getting stuck in local minima. We shall clarify these loss functions in the following summarization.\n",
    "\n",
    "#### Summarizing a variant of the A2C algorithm:\n",
    "> For many iterations repeat:\n",
    "1. Collect $N$ independent trajectories $\\{ (s_t^{i},a_t^{i},r_t^{i})_{t=0}^T \\}_{i=1}^{N}$ by running policy $\\pi_{\\theta}$ for maximum $T$ steps;\n",
    "2. Compute the loss function for the policy parameter $\\theta$:\n",
    "$$\n",
    "L_{policy}(\\theta) = \\frac1{NT} \\sum_{i=1}^N \\sum_{t=0}^T \\left( \\log \\pi_{\\theta} (s_t^{i}, a_t^{i}) \\left( \\sum_{t'=t}^T \\gamma^{t'-t} r_{t'}^{i} - V_{\\phi}(s_t^{i}) \\right) \\right)\n",
    "$$\n",
    "Compute the entropy term for $\\theta$:\n",
    "$$\n",
    "L_{entropy}(\\theta) = \\frac1{NT} \\sum_{i=1}^N \\sum_{t=0}^T \\left( - \\sum_{a\\in A} \\pi_{\\theta}(s_t^{i}, a) \\log \\pi_{\\theta}(s_t^{i}, a) \\right)\n",
    "$$\n",
    "Compute the loss for value function parameter $\\phi$:\n",
    "$$\n",
    "L_{value}(\\phi) = \\frac1{NT} \\sum_{i=1}^N \\sum_{t=0}^T \\left( \\sum_{t'=t}^T \\gamma^{t'-t} r_{t'}^{i} - V_{\\phi}(s_t^{i}) \\right)^2\n",
    "$$\n",
    "3. Use pytorch auto-differentiation and optimizer to do one gradient step on $(\\theta, \\phi)$ with the overall loss:\n",
    "$$\n",
    "L(\\theta, \\phi) = - L_{policy} - \\lambda_{ent} L_{entropy} + \\lambda_{val} L_{value}\n",
    "$$\n",
    "where $\\lambda_{ent}$ and $\\lambda_{val}$ are coefficients to balances the loss terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C4 (10 pts): Complete the code for computing the advantange, entropy and loss function in `A2C.train` in file `Algo.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### P2 (10 pts): Run A2C on CartPole and plot the learning curve (i.e. averaged episodic reward against training iteration).\n",
    "Your code should be able to achieve **>150** averaged reward in 10000 iterations (40000 simulation steps) in only a few minutes. This is a good indication that the implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(algo='a2c', batch_size=64, checkpoint_freq=20000, discount=0.996, ent_coef=0.01, env='CartPole-v1', eps_decay=200000, frame_skip=1, frame_stack=4, load='', log='log.txt', lr=0.001, niter=10000, nproc=4, parallel_env=0, print_freq=200, replay_size=1000000, save_dir='cartpole_a2c/', target_update=2500, train_freq=16, train_start=0, value_coef=0.01)\n",
      "observation space: Box(4,)\n",
      "action space: Discrete(2)\n",
      "running on device cpu\n",
      "shared net = False, parameters to optimize: [('fc1.weight', torch.Size([128, 4]), True), ('fc1.bias', torch.Size([128]), True), ('fc2.weight', torch.Size([2, 128]), True), ('fc2.bias', torch.Size([2]), True), ('fc1.weight', torch.Size([128, 4]), True), ('fc1.bias', torch.Size([128]), True), ('fc2.weight', torch.Size([1, 128]), True), ('fc2.bias', torch.Size([1]), True)] \n",
      "\n",
      "obses on reset: 4 x (4,) float32\n",
      "iter    200 |loss   1.00 |n_ep    37 |ep_len   18.8 |ep_rew  18.76 |raw_ep_rew  18.76 |env_step    800 |time 00:00 rem 00:06\n",
      "iter    400 |loss   0.79 |n_ep    74 |ep_len   20.1 |ep_rew  20.14 |raw_ep_rew  20.14 |env_step   1600 |time 00:00 rem 00:05\n",
      "iter    600 |loss   0.71 |n_ep   101 |ep_len   28.7 |ep_rew  28.66 |raw_ep_rew  28.66 |env_step   2400 |time 00:00 rem 00:05\n",
      "iter    800 |loss   1.02 |n_ep   129 |ep_len   27.0 |ep_rew  27.03 |raw_ep_rew  27.03 |env_step   3200 |time 00:00 rem 00:04\n",
      "iter   1000 |loss   1.02 |n_ep   151 |ep_len   39.2 |ep_rew  39.23 |raw_ep_rew  39.23 |env_step   4000 |time 00:00 rem 00:04\n",
      "iter   1200 |loss   0.77 |n_ep   173 |ep_len   36.3 |ep_rew  36.27 |raw_ep_rew  36.27 |env_step   4800 |time 00:00 rem 00:04\n",
      "iter   1400 |loss   0.84 |n_ep   195 |ep_len   36.3 |ep_rew  36.29 |raw_ep_rew  36.29 |env_step   5600 |time 00:00 rem 00:04\n",
      "iter   1600 |loss   0.97 |n_ep   214 |ep_len   35.1 |ep_rew  35.09 |raw_ep_rew  35.09 |env_step   6400 |time 00:00 rem 00:04\n",
      "iter   1800 |loss   0.82 |n_ep   236 |ep_len   36.4 |ep_rew  36.40 |raw_ep_rew  36.40 |env_step   7200 |time 00:00 rem 00:04\n",
      "iter   2000 |loss   0.65 |n_ep   262 |ep_len   27.1 |ep_rew  27.14 |raw_ep_rew  27.14 |env_step   8000 |time 00:01 rem 00:04\n",
      "iter   2200 |loss   0.65 |n_ep   281 |ep_len   38.4 |ep_rew  38.38 |raw_ep_rew  38.38 |env_step   8800 |time 00:01 rem 00:04\n",
      "iter   2400 |loss   0.68 |n_ep   299 |ep_len   39.6 |ep_rew  39.63 |raw_ep_rew  39.63 |env_step   9600 |time 00:01 rem 00:03\n",
      "iter   2600 |loss   0.74 |n_ep   318 |ep_len   45.1 |ep_rew  45.09 |raw_ep_rew  45.09 |env_step  10400 |time 00:01 rem 00:03\n",
      "iter   2800 |loss   0.69 |n_ep   330 |ep_len   46.5 |ep_rew  46.49 |raw_ep_rew  46.49 |env_step  11200 |time 00:01 rem 00:03\n",
      "iter   3000 |loss   0.87 |n_ep   348 |ep_len   44.8 |ep_rew  44.76 |raw_ep_rew  44.76 |env_step  12000 |time 00:01 rem 00:03\n",
      "iter   3200 |loss   0.44 |n_ep   369 |ep_len   37.2 |ep_rew  37.18 |raw_ep_rew  37.18 |env_step  12800 |time 00:01 rem 00:03\n",
      "iter   3400 |loss   0.99 |n_ep   384 |ep_len   44.1 |ep_rew  44.14 |raw_ep_rew  44.14 |env_step  13600 |time 00:01 rem 00:03\n",
      "iter   3600 |loss   0.06 |n_ep   398 |ep_len   58.3 |ep_rew  58.30 |raw_ep_rew  58.30 |env_step  14400 |time 00:01 rem 00:03\n",
      "iter   3800 |loss   0.78 |n_ep   411 |ep_len   51.5 |ep_rew  51.49 |raw_ep_rew  51.49 |env_step  15200 |time 00:01 rem 00:03\n",
      "iter   4000 |loss   0.59 |n_ep   419 |ep_len   56.7 |ep_rew  56.68 |raw_ep_rew  56.68 |env_step  16000 |time 00:02 rem 00:03\n",
      "iter   4200 |loss   0.12 |n_ep   431 |ep_len   79.2 |ep_rew  79.25 |raw_ep_rew  79.25 |env_step  16800 |time 00:02 rem 00:03\n",
      "iter   4400 |loss   0.11 |n_ep   437 |ep_len  105.9 |ep_rew 105.86 |raw_ep_rew 105.86 |env_step  17600 |time 00:02 rem 00:02\n",
      "iter   4600 |loss   0.89 |n_ep   447 |ep_len   95.1 |ep_rew  95.15 |raw_ep_rew  95.15 |env_step  18400 |time 00:02 rem 00:02\n",
      "iter   4800 |loss   0.42 |n_ep   453 |ep_len  100.4 |ep_rew 100.42 |raw_ep_rew 100.42 |env_step  19200 |time 00:02 rem 00:02\n",
      "iter   5000 |loss   0.25 |n_ep   461 |ep_len  101.3 |ep_rew 101.26 |raw_ep_rew 101.26 |env_step  20000 |time 00:02 rem 00:02\n",
      "iter   5200 |loss   0.27 |n_ep   468 |ep_len  104.7 |ep_rew 104.72 |raw_ep_rew 104.72 |env_step  20800 |time 00:02 rem 00:02\n",
      "iter   5400 |loss   0.75 |n_ep   475 |ep_len  106.6 |ep_rew 106.56 |raw_ep_rew 106.56 |env_step  21600 |time 00:02 rem 00:02\n",
      "iter   5600 |loss   0.49 |n_ep   481 |ep_len  122.9 |ep_rew 122.88 |raw_ep_rew 122.88 |env_step  22400 |time 00:02 rem 00:02\n",
      "iter   5800 |loss   0.82 |n_ep   486 |ep_len  116.9 |ep_rew 116.91 |raw_ep_rew 116.91 |env_step  23200 |time 00:03 rem 00:02\n",
      "iter   6000 |loss   0.97 |n_ep   494 |ep_len  130.4 |ep_rew 130.44 |raw_ep_rew 130.44 |env_step  24000 |time 00:03 rem 00:02\n",
      "iter   6200 |loss   0.15 |n_ep   497 |ep_len  149.9 |ep_rew 149.88 |raw_ep_rew 149.88 |env_step  24800 |time 00:03 rem 00:02\n",
      "iter   6400 |loss   0.72 |n_ep   500 |ep_len  168.2 |ep_rew 168.23 |raw_ep_rew 168.23 |env_step  25600 |time 00:03 rem 00:01\n",
      "iter   6600 |loss   0.86 |n_ep   506 |ep_len  165.1 |ep_rew 165.10 |raw_ep_rew 165.10 |env_step  26400 |time 00:03 rem 00:01\n",
      "iter   6800 |loss   0.80 |n_ep   510 |ep_len  161.6 |ep_rew 161.57 |raw_ep_rew 161.57 |env_step  27200 |time 00:03 rem 00:01\n",
      "iter   7000 |loss   0.72 |n_ep   513 |ep_len  181.8 |ep_rew 181.84 |raw_ep_rew 181.84 |env_step  28000 |time 00:03 rem 00:01\n",
      "iter   7200 |loss   0.62 |n_ep   518 |ep_len  186.8 |ep_rew 186.82 |raw_ep_rew 186.82 |env_step  28800 |time 00:03 rem 00:01\n",
      "iter   7400 |loss  -0.01 |n_ep   523 |ep_len  163.1 |ep_rew 163.12 |raw_ep_rew 163.12 |env_step  29600 |time 00:03 rem 00:01\n",
      "iter   7600 |loss   0.00 |n_ep   525 |ep_len  210.5 |ep_rew 210.53 |raw_ep_rew 210.53 |env_step  30400 |time 00:04 rem 00:01\n",
      "iter   7800 |loss   0.72 |n_ep   531 |ep_len  187.4 |ep_rew 187.42 |raw_ep_rew 187.42 |env_step  31200 |time 00:04 rem 00:01\n",
      "iter   8000 |loss   0.02 |n_ep   536 |ep_len  178.3 |ep_rew 178.31 |raw_ep_rew 178.31 |env_step  32000 |time 00:04 rem 00:01\n",
      "iter   8200 |loss  -0.12 |n_ep   540 |ep_len  178.0 |ep_rew 177.97 |raw_ep_rew 177.97 |env_step  32800 |time 00:04 rem 00:00\n",
      "iter   8400 |loss  -0.20 |n_ep   545 |ep_len  186.9 |ep_rew 186.86 |raw_ep_rew 186.86 |env_step  33600 |time 00:04 rem 00:00\n",
      "iter   8600 |loss   0.80 |n_ep   549 |ep_len  160.5 |ep_rew 160.53 |raw_ep_rew 160.53 |env_step  34400 |time 00:04 rem 00:00\n",
      "iter   8800 |loss   0.13 |n_ep   556 |ep_len  148.5 |ep_rew 148.50 |raw_ep_rew 148.50 |env_step  35200 |time 00:04 rem 00:00\n",
      "iter   9000 |loss   0.86 |n_ep   562 |ep_len  129.8 |ep_rew 129.80 |raw_ep_rew 129.80 |env_step  36000 |time 00:04 rem 00:00\n",
      "iter   9200 |loss  -0.26 |n_ep   571 |ep_len  125.2 |ep_rew 125.18 |raw_ep_rew 125.18 |env_step  36800 |time 00:04 rem 00:00\n",
      "iter   9400 |loss   0.13 |n_ep   576 |ep_len  124.2 |ep_rew 124.16 |raw_ep_rew 124.16 |env_step  37600 |time 00:04 rem 00:00\n",
      "iter   9600 |loss  -0.39 |n_ep   583 |ep_len  127.5 |ep_rew 127.53 |raw_ep_rew 127.53 |env_step  38400 |time 00:05 rem 00:00\n",
      "iter   9800 |loss   0.64 |n_ep   589 |ep_len  115.3 |ep_rew 115.28 |raw_ep_rew 115.28 |env_step  39200 |time 00:05 rem 00:00\n",
      "save checkpoint to cartpole_a2c/9999.pth\n"
     ]
    }
   ],
   "source": [
    "%run Main.py  \\\n",
    "    --niter 10000   \\\n",
    "    --env CartPole-v1   \\\n",
    "    --algo a2c  \\\n",
    "    --nproc 4   \\\n",
    "    --lr 0.001  \\\n",
    "    --train_freq 16 \\\n",
    "    --train_start 0 \\\n",
    "    --batch_size 64     \\\n",
    "    --discount 0.996    \\\n",
    "    --value_coef 0.01    \\\n",
    "    --print_freq 200    \\\n",
    "    --checkpoint_freq 20000 \\\n",
    "    --save_dir cartpole_a2c \\\n",
    "    --log log.txt \\\n",
    "    --parallel_env 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curve('cartpole_a2c/log.txt', 'CartPole A2C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's play a little bit with the trained agent. The neural net parameters are saved to the `cartpole_dqn` and `cartpole_a2c` folders. The cell below will open a window showing one episode play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared net = False, parameters to optimize: [('fc1.weight', torch.Size([128, 4]), True), ('fc1.bias', torch.Size([128]), True), ('fc2.weight', torch.Size([2, 128]), True), ('fc2.bias', torch.Size([2]), True), ('fc1.weight', torch.Size([128, 4]), True), ('fc1.bias', torch.Size([128]), True), ('fc2.weight', torch.Size([1, 128]), True), ('fc2.bias', torch.Size([1]), True)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gym\n",
    "import Algo\n",
    "env = gym.make('CartPole-v1')\n",
    "agent = Algo.ActorCritic(env.observation_space, env.action_space)\n",
    "agent.load('cartpole_a2c/9999.pth')\n",
    "state = env.reset()\n",
    "for _ in range(120):\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(agent.act([state])[0])\n",
    "    if done: break\n",
    "    time.sleep(0.1)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Solve the Atari Breakout game\n",
    "***\n",
    "In this part, you'll train your agent to play Breakout with the BlueWaters cluster. I have provided the job scripts for you. Please upload your `Algo.py` and `Model.py` completed in **Part I** to your BlueWaters folder. And submit the following two jobs respectively:\n",
    "```\n",
    "qsub run_dqn.pbs\n",
    "qsub run_a2c.pbs\n",
    "```\n",
    "\n",
    "The jobs are set to run for at most **14 hours**. **<font color=red>Please start early!!</font>** You might be able to reach the desired score (>= 200 reward) before 14 hours - You can stop the training early if you wish. Then please collect the resulting `breakout_dqn/log.txt` and `breakout_a2c/log.txt` files into the same folder as this Jupyter notebook's. Rename them as `log_breakout_dqn.txt` and `log_breakout_a2c.txt`.\n",
    "\n",
    "BTW, there's an Atari PC simulator: https://stella-emu.github.io/ I spent a lot of time playing them..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C5 (10 pts): Complete the code for the CNN with 3 conv layers and 3 fc layers in class `SimpleCNN` in file `Model.py`\n",
    "And verify the output shape with the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN output shape test passed!\n"
     ]
    }
   ],
   "source": [
    "## Test code\n",
    "from Model import SimpleCNN\n",
    "import torch\n",
    "net = SimpleCNN()\n",
    "x = torch.randn(2, 4, 84, 84)\n",
    "y = net(x)\n",
    "assert y.shape == (2, 4), \"ERROR: network output has the wrong shape!\"\n",
    "print (\"CNN output shape test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### P3 (10 pts): Run the following cell to generate a DQN learning curve.\n",
    "The *maximum* average episodic reward on this curve should be larger than $200$ for full credit. (It's ok if the final reward is not as high.) The typical value is around $300$. You get 70% credit if $100 \\le$ average episodic reward $< 200$, 50% credit if $50 \\le$ average episodic reward $< 100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve('log_breakout_dqn.txt', 'Breakout DQN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### P4 (10 pts): Run the following cell to generate an A2C learning curve.\n",
    "The *maximum* average episodic reward on this curve should be larger than $150$ for full credit. (It's ok if the final reward is not as high.) The typical value is around $250$. You get 70% credit if $50 \\le$ average episodic reward $< 150$, and 50% credit if $20 \\le$ average episodic reward $< 50$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve('log_breakout_a2c.txt', 'Breakout A2C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### P5 (10 pts): Collect and visualize some game frames by running the script `Draw.py` on BlueWaters.\n",
    "(1) `module load python/2.0.0` and run `Draw.py` on BlueWaters (it's ok to run this locally, no need to start a job).\n",
    "\n",
    "(2) Download the result `breakout_imgs` folder from BlueWaters to the folder containing this Jupyter notebook, and run the following cell. You should see some animation of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "imgs = sorted(os.listdir('breakout_imgs'))\n",
    "#imgs = [plt.imread('breakout_imgs/' + img) for img in imgs]\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "pimg = None\n",
    "for img in imgs:\n",
    "    img = plt.imread('breakout_imgs/' + img)\n",
    "    if pimg:\n",
    "        pimg.set_data(img)\n",
    "    else:\n",
    "        pimg = plt.imshow(img)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Questions (10 pts)\n",
    "***\n",
    "\n",
    "These are open-ended questions. The purpose is to encourage you to think (a bit) more deeply about these algorithms. You get full points as long as you write a few sentences that make sense and show some thinking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q1 (2 pts): Why would people want to do function approximation rather than using tabular algorithm (on discretized S,A spaces if necessary)? Bringing function approximation has caused numerous problems theoretically (e.g. not guaranteed to converge), so it seems not worth it..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer: I don't know. People enjoy \"neuralizing\" things I guess.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q2 (2 pts): Q-Learning seems good... it's theoretically sound (at least seems to be), the performance is also good. Why would many people actually prefer policy gradient type algorithms in some practical problems?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer: I don't know. I like Q learning. The name is cute. Anyone watch StarTrek?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3 (2 pts): Does the policy gradient algorithm (A2C) we implemented here extend to continuous action space? How would you do that? Hint: What is a reasonable distribution assumption for policy $\\pi_{\\theta}(a|s)$ if $a$ lives in continuous space?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer: I don't know. Maybe normalizing flow?? OK, people really do this..(arXiv:1905.06893) Hot area + hot area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q4 (2 pts): The policy gradient algorithm (A2C) we implemented uses on-policy data. Can you think of a way to extend it to utilize off-policy data? Hint: Importance sampling, needs some approximation though"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer: I don't know. Do random math tricks or pray?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5 (2 pts): How to compare different RL algorithms? When can I say one algorithm is better than the other? Hint: This question is quite open. Think about speed, complexity, tasks, etc."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your answer: I don't know. Just pick one you like, they're equally bad.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
